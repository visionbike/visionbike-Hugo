[{"content":"Since pre-built OpenCV binaries do not include CUDA modules, this post is a tutorial for building OpenCV with CUDA on Windows 11. The obvious dvantage of OpenCV CUDA is boosting performance of most functions, you can find evidence here.\n1. Prerequisite There are a couples of softwares or libraries having been downloaded and installed before getting started:\nInstall the Visual Studio Community 2022 and select Desktop development with C++ workload.\nDownload the sources for OpenCV from GitHub by cloning the repositories (opencv and opencv_contrib).\nAfter downloading, you can indicate the OpenCV\u0026rsquo;s version you want to. For the current version, you can run the following command in Command Prompt at OpenCV\u0026rsquo;s repositories:\ngit checkout tags/4.8.0 Install the latest stable version (not release candidate -rc) of CMake.\nInstall the latest version of NVIDIA CUDA Toolkit and add PATH. You can follow this tutorial.\nThe latest CUDA Toolkit version\nAt the time writting this post, the latest NVIDIA CUDA Toolkit version 12.2 still makes somes error when building with OpenCV 4.8.0, like error C2666: 'operator !=': overloaded functions have similar conversions. Therefore, if meeting such problem, try installing older version.\nRegister an account and download the latest verson of NVIDIA DNN CUDA backend for the version of CUDA. Extract the downloaded .zip file and copy bin, include and lib directories to your CUDA installation directory, i.e., C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\vxx.x.\nRegister an account and download the latest version of NVIDIA VIdeo Codec SDK. Extract the downloaded .zip file and copy the contents inside Interface and Lib to include and lib directories inside the CUDA installation directory.\nOptional - Download and install the latest version of Gstreamer.\nDownload and install the lastest version of mambaforge to call OpenCV CUDA routines from python.\n2. Create virtual environtment from Mambaforge To bind OpenCV for python3 without any conflit package installation, you should create an new virtual environment for the installation.\nmamba create -n opencv-cuda python=3.10 Activate the created environment and install numpy package.\nmamba activate opencv-cuda mamaba install numpy 3. Build OpenCV with CMake Preparation Create a build folder with your OpenCV extracted folders.\nEdit the prioeiry of Python3 installation in OpenCVDetectPython.cmake file inside opencv-x.x.x/cmake folder.\nBuild GUI Build Configuration Open Cmake GUI and provide the paths to the OpenCV and target build folders.\nHit Configure and select x64 for the Optional platform for generator, then hit finish to start the configuration.\nOnce the configuration is done, edit the following parameters:\nParameter Value CMAKE_INSTALL_PREFIX path of opencv installation ENABLE_FAST_MATH âœ… WITH_CUDA âœ… BUILD_opencv_world âœ… BUILD_opencv_python3 âœ… OPENCV_DNN_CUDA âœ… OPENCV_EXTRA_MODULES_PATH path of modules directory in opencv_contrib-x.x.x OPENCV_PYTHON3_VERSION âœ… PYTHON3_EXECUTABLE path of python3 executable in virtual env, i.e., C:/Users/ntthi/mambaforge/envs/opencv-cuda/python.exe PYTHON3_INCLUDE_DIR path of include folder in the virtual env, i.e., C:/Users/ntthi/mambaforge/envs/opencv-cuda/include PYTHON3_LIBRARY path of .lib file in the virtual env, i.e., C:/Users/ntthi/mambaforge/envs/opencv-cuda/libs/python310.lib PYTHON3_NUMPY_INCLUDE_DIRS path of numpy in the virtual env, i.e., C:/Users/ntthi/mambaforge/envs/opencv-cuda/Lib/site-pakages/numpy/core/include PYTHON3_PACKAGES_PATH path of site-packages in the virtual env, i.e., C:/Users/ntthi/mambaforge/envs/opencv-cuda/Lib/site-pakages Note that the path separator hase to be \u0026ldquo;/\u0026rdquo; , not \u0026ldquo;\u0026quot;.\nHit Configure again again and check edit more parameters:\nParameter Value CUDA_FAST_MATH âœ… CUDA_ARCH_BIN version of computing capability, i.e., 8.6 WITH_CUBLAS âœ… WITH_CUDNN âœ… WITH_CUFFT âœ… The CUDA_ARCH_BIN corresponding to your GPU is the value found in the left column of the GPU support table. For instance, \u0026ldquo;8.6\u0026rdquo; fir the RTX 3070 Ti.\nIf you do not want to create shared lib and make sure the opencv python libraries is installed, edit the following parameters:\nParameter Value BUILD_SHARED_LIBS ðŸ”³ OPENCV_FORCE_PYTHON_LIBS âœ… Hit Configure at the last time and then hit Generate.\nBuild the project with Visual Studio Open project OpenCV.sln created in the build folder. Go to Tools \u0026gt; Options\u0026hellip;, then uncheck the last parameter in Projects and Solutions \u0026gt; Web Projects.\nThis setting may help to prevent the ImportError: DLL load failed while importing cv2: The specified module could not be found. error.\nTo build the OpenCV project, change Debug mode to Release. In the solution explorer expand CMakeTargets, right-click ALL_BUILD and select Build. This will take about an hour.\nThen repeat the step for INSTALL (below ALL_BUILD). Check for error in the two building steps. If everything is fine, you are done.\nCheck Installation and Troubleshooting To verify the Python installation, activate the virtual environment for OpenCV install and try this code:\nimport cv2 print(cv2.__version__) print(cv2.cuda.getCudaEnabledDeviceCount()) If it works, congratulations you are good to go!\nIf you meets the problem ImportError: DLL load failed while importing cv2: The specified module could not be found., it may lack the library\u0026rsquo;s binaries. One solution is to edit config.py in C:/Users/ntthi/mambaforge/envs/opencv-cuda/Lib/site-packages/cv2.\nimport os BINARIES_PATHS = [ os.path.join(\u0026#39;C:/opencv-cuda-4.8.0\u0026#39;, \u0026#39;x64/vc17/bin\u0026#39;), os.path.join(os.getenv(\u0026#39;CUDA_PATH\u0026#39;, \u0026#39;C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.1\u0026#39;), \u0026#39;bin\u0026#39;), os.path.join(\u0026#39;C:/gstreamer/1.0/msvc_x86_64\u0026#39;, \u0026#39;bin\u0026#39;), ] + BINARIES_PATHS These binary paths are from installed OpenCV, CUDA and Gstreamer (if installed).\nFor other bugs and problems, I refer you to the chrismeunier and Bowley\u0026rsquo;s troubleshooting tutorial.\nReference Build OpenCV (including Python) with CUDA on Windows. OpenCV CUDA installation. ","permalink":"http://visionbike.github.io/posts/build-opencv-cuda-on-windows/","summary":"Since pre-built OpenCV binaries do not include CUDA modules, this post is a tutorial for building OpenCV with CUDA on Windows 11. The obvious dvantage of OpenCV CUDA is boosting performance of most functions, you can find evidence here.\n1. Prerequisite There are a couples of softwares or libraries having been downloaded and installed before getting started:\nInstall the Visual Studio Community 2022 and select Desktop development with C++ workload.","title":"Build OpenCV with CUDA on Windows 11"},{"content":"To get started with running CUDA on WSL, you need to instal NVIDIA Driver on Windows 11 with a compatible GeForce or NVIDIA RTX/Quadro card from this link.\nNote that you only need to install NVIDIA Driver for Windows. Do not install any Linux Driver in WSL.\nThe latest NVIDIA Windows GPU Driver will fully support WSL 2. With CUDA support in the driver, existing applications compiled on a Linux system for the same target GPU can run unmodified within the WSL environment. Once NVIDIA Windows GPU Driver is installed in the system, the CUDA driver will be stubbed inside the WSL 2 as libcuda.so. Therefore, you only use a separate CUDA Toolkit for WSL 2 which does not contain the NVIDIA Linux GPU Driver.\n1. Install NVIDIA CUDA Toolkit for WSL 2 First remove the old GPG key from your WSL machine\nsudo apt-key del 7fa2af80 Download CUDA Toolkit for WSL 2.\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/12.2.1/local_installers/cuda-repo-wsl-ubuntu-12-2-local_12.2.1-1_amd64.deb Then, folow the installation instruction.\nsudo dpkg -i cuda-repo-wsl-ubuntu-12-2-local_12.2.1-1_amd64.deb sudo cp /var/cuda-repo-wsl-ubuntu-12-2-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda Verify that CUDA is successfully installed by command\nnvidia-smi 2. Install NVIDIA CuDNN You can find the coresponding installation file from this. Here you need to register and login to download it.\nYou can use Windows to download installation files then move to Ubuntu system in WSL 2. The WSL system is mapped to \\\\wsl$\\Ubuntu-22.04 and Windows drives are mounted under /mnt and can be accessed directly.\nOnce completed, it can be installed with following commands\nsudo dpkg -i cudnn-local-repo-ubuntu2204-8.9.3.28_1.0-1_amd64.deb sudo cp /var/cudnn-local-repo-ubuntu2204-8.9.3.28/cudnn-local-*-keyring.gpg /usr/share/keyrings/ sudo apt-get -y update sudo apt-get -y upgrade Fix \u0026#34;libcuda.so.1 is not a symbolic link\u0026#34; error Once the installattion is completed, you may receive the following error:\n/sbin/ldconfig.real: /usr/lib/wsl/lib/libcuda.so.1 is not a symbolic link The reason may be the property of read-only of the directory. You can create other directory then link executable from /usr/lib/wsl/lib/ to the new directory.\ncd /usr/lib/wsl sudo mkdir lib2 sudo ln -s lib/* lib2 sudo ldconfig Then change /usr/lib/wsl/lib in the file /etc/ld.so.conf.d/ld.wsl.conf to /usr/lib/wsl/lib2.\n# This file was automatically generated by WSL. To stop automatic generation of this file, add the following entry to /etc/wsl.conf: #[automount] #ldconfig = false /usr/lib/wsl/lib2 Restarting WSL after setting will automatically restore, if you donâ€™t want to restore, you need to modif /etc/wsl.conf\n[automount] ldconfig = false 3. Set up Python environment using Mambaforge Python environment allows to manage separatelly different installations of Python and modules. It is useful when you have many projects running different version of Python and modules. It also help to manage installed modules for publish or reproduce.\nThere are different ways to create a python virtual environment, including built-in venv, Conda and Anaconda.\nConda is a packaging tool and installer that aims to handle library dependencies outside of the Python packages as well as the Python packages themselves. For non preinstalled package manager, Miniconda, an installation of Conda, will be a good option.\nAnaconda is an installation of Conda that comes pre-loaded with a bunch of packages for scientific computing, i.e., numpy, matplotlib, scipy, etc. It also comes with IDE, Jupyter notebooks out of the box. This is helpful for beginers, but doesn\u0026rsquo;t give much control.\nMamba is a package manager which can be used with Python. Unlike Conda, it uses the C/C++ implementation to speed up the package installation. Read more about mamba in here. To install mamba, access its repo and pick the Mabaforge installer for your operating system.\nRemember to run conda init at the end of your installation in your shell to activate the mamba command.\nCreate and use virtual environments The command using mamba is similar to the conda command.\nCreate new environment mamba create -n \u0026lt;envname\u0026gt; python=\u0026lt;version\u0026gt; Activate an environment mamba activate \u0026lt;envname\u0026gt; Deactivate environment mamba deactivate Delete an environment mamba env remove -n \u0026lt;envname\u0026gt; Show all created environments mamba env list Working with Python packages Remember to activate an environment first, do not install any packages in your base environment!\nInstall python packages mamba install \u0026lt;package\u0026gt;[=version] [-c \u0026lt;channelname\u0026gt;] When installing a package, you can optionally indicate specific additional channel that the packages are posted by community. conda-forge is one of most common additional channels.\nDelete packages mamba remove \u0026lt;package\u0026gt; Show all installed packages in the virtual environment mamba list [-n \u0026lt;envname\u0026gt;] Reference Install CUDA and CUDNN on Windows \u0026amp; Linux. CUDA on WSL User Guide. Machine learning environment build: WLS2+Ubuntu+CUDA+cuDNN. Getting started with Mambaforge and Python. Tutorial: Setting up Python enviroments with Mambaforge. ","permalink":"http://visionbike.github.io/posts/create-ml-development-environment-on-windows11-with-wsl2/","summary":"To get started with running CUDA on WSL, you need to instal NVIDIA Driver on Windows 11 with a compatible GeForce or NVIDIA RTX/Quadro card from this link.\nNote that you only need to install NVIDIA Driver for Windows. Do not install any Linux Driver in WSL.\nThe latest NVIDIA Windows GPU Driver will fully support WSL 2. With CUDA support in the driver, existing applications compiled on a Linux system for the same target GPU can run unmodified within the WSL environment.","title":"Setting Up NVIDIA CUDA on Windows 11 With WSL 2"},{"content":"Windows Subsystem for Linux (WSL) is a compatibility layer provided by Microsoft that allows you to run a Linux environment directly on your Windows operating system. It enables you to execute Linux binaries, use Linux command-line tools, and access Linux file systems from within Windows.\nWhen it comes to machine learning (ML) development, WSL offers several advantages:\nLinux Compatibility: Many ML frameworks, libraries, and tools are primarily developed and optimized for Linux systems. By using WSL, you can seamlessly run Linux-specific ML software on your Windows machine without the need for dual-booting or setting up a separate Linux machine.\nAccess to Linux Packages: WSL provides access to the extensive collection of Linux packages available in various package managers (e.g., APT, YUM, and others). This allows you to easily install and manage Linux dependencies required for your ML projects.\nCommand-Line Tools and Scripts: ML development often involves working with command-line tools and executing scripts. WSL provides a Linux shell environment, enabling you to run Linux commands and scripts directly on your Windows machine. This ensures compatibility and smooth execution of ML workflows that rely on Linux-specific commands and scripts.\nCompatibility with Docker: Docker is widely used in ML development to create isolated environments for running ML applications. WSL provides a seamless integration with Docker, allowing you to run Linux-based Docker containers on your Windows machine without any performance overhead.\nConsistency across Development Environments: If you work in a team where some members use Linux for ML development, using WSL allows you to maintain consistency across different development environments. It ensures that code, scripts, and configurations work consistently regardless of the underlying operating system.\nBy utilizing WSL, you can leverage the power of Linux for ML development while enjoying the convenience of working within the Windows environment. It bridges the gap between Windows and Linux, making it easier to set up and manage a Linux-based ML environment on your Windows machine.\nIt is important to note that WSL is available in different versions, such as WSL 1 and WSL 2. WSL 2 offers enhanced performance and better integration with the Windows system, making it the recommended choice for ML development. The WSL 2 is fully integrated in Windows 10 build 19041 or Windows 11, so you may consider upgrade your system before install it.\nCheck Windows Version\nYou can check Window version by going to Settings \u0026gt; System \u0026gt; About and scroll down to Windows specifications.\nIf you plan to work with Linux-based ML frameworks, libraries, or tools, using WSL can significantly streamline your development workflow and ensure compatibility with the wider ML community.\n1. PC Requirements WSL 2 uses Hyper-V which requires harware virtualization support enabled in your BIOS. To ensure the hardware virtualization is available on your device, you can check by rebooting, pressing DEL, F2 or F10 (depending on the hardware manufacture) to open the BIOS pannels. Lokking for Virtualization Technology, VTx, Secure Virtual Machine (SVM) or similar options and ensure these options enabled, then reboot the machine.\nDisable Fast Start-up (Optional) Fast start-up saves Windows session and device drivers to a file so the next boot become faster. However, this can cause problems for Linux kernel, which may unresponsive on the next boost. If you encounter this problem, you can disable tthe fast start-up option by Control Panel \u0026gt; Power Options \u0026gt; Choose what the power buttons do \u0026gt; Change settings that are currently unavailable\n2. Install Docker Desktop Docker Desktop with WSL 2 provides an efficient and seamless integration between Docker containers and the WSL 2 environment. This combination allows you to run Linux containers directly on your Windows system, leveraging the power of WSL 2.\nIf you haven\u0026rsquo;t installed Docker Desktop yet, please download and install the Docker Desktop for Windows from the Docker website. Installing Docker Desktop on Windows enables docker and docker-compose in both Windows and WSL 2.\nDocker Desktop suggests you use WSL 2 when it\u0026rsquo;s first launched. Alternatively, you can select Settings from the Docker system tray icon menu, then choose the General tab, check Use the WSL 2 based engine, and hit Apply \u0026amp; Restart. Docker uses the default Linux distro, but you can also enable it in other installed distros from the WSL Integration panel in Settings, then Resources.\nOnce Docker Desktop is installed, you can verify that it is running correctly by following command from PowerShell or Command Prompt:\ndocker version This command displays the Docker version and confirms that Docker is running with WSL 2 integration.\nBy combining Docker Desktop with WSL 2, you can take advantage of the containerization capabilities of Docker while benefiting from the compatibility and performance enhancements of WSL 2. It allows for efficient development and deployment of applications in a Linux environment, even if you\u0026rsquo;re working on a Windows system.\n3. Install Windows Terminal Windows Terminal is a powerful and customizable terminal application for Windows that provides a modern and feature-rich command-line experience. It allows you to interact with various shells and command-line tools in a single window, making it convenient for developers and system administrators. It is available from the Microsoft Store or it repository at github.com/microsoft/terminal/.\nWindows Terminal automatically adds WSL 2 Linux distros when they\u0026rsquo;re installed and offers a configurable range of options including tabs, split views, themes, transparency, and key bindings.\n4. Install Windows Subsystem for Linux 2 (WSL 2) To display a list of available WSL Linux distros, you can run followinf command in PowerShell in adminitror mode:\nwsl --list --online To install the default Ubuntu distro (the latest version), run:\nwsl --install If you want to install a specific distro by name, such as Ubuntu-22.04, run:\nwsl --install -d Ubuntu-22.04 Install WSL Distros from Microsoft Store Alternaltively, you can install Linux distro from the Microsoft Store.\nOnce the installation is done, you will be prompted to enter a username and password. These are the credentials for Linux administration and completely separately from your Windows username.\nPlease create a default UNIX user account. The username does not need to match your Windows username. For more information visit: https://aka.ms/wslusers Enter new UNIX username: Visionbike New password: Retype new password: paddwd: password updated successfully Installation successful! Linux will eventually be ready and your terminal will show content similar to:\nTo run a command as administrator (user \u0026#34;root\u0026#34;), use \u0026#34;sudo \u0026lt;command\u0026gt;\u0026#34;. See \u0026#34;man sudo_root\u0026#34; for details. Welcome to Ubuntu 22.04.2 LTS (GNU/Linux 5.15.90.1-microsoft-standard-WSL2 x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s just raised the bar for easy, resilient and secure K8s cluster deployment. https://ubuntu.com/engage/secure-kubernetes-at-the-edge This message is shown once a day. To disable it please create the /home/visionbike/.hushlogin file. For the first start, we should to install several Linux updates. The process will depend on the speed of the internet, so be patient if it slow!\nsudo apt update \u0026amp;\u0026amp; sudo apt upgrade You can also to check for Linux kernel updates from PowerShell running:\nwsl --update Verify WSL 2 Installation\nTo check if the installation was successful, you can run the following command in PowerShell:\nwsl -l -v NAME STATE VERSION * Ubuntu-22.04 Running 2 docker-desktop Stopped 2 docker-desktop-data Stopped 2 5. Working with WSL 2 Set a Default Linux Distribution If you have more than one WSL Linu distro, you need to set the most frequent used distro as a default one. To set the default distro, run the following command in PowerShell temrinal.\nwsl --setdefault \u0026lt;DISTRONAME\u0026gt; where \u0026lt;DISTRONAME\u0026gt; is the distro\u0026rsquo;s name you installed.\nFile System in WLS 2 In WSL 2, the Linux file system is located within the WSL 2 virtual machine. It provides a Linux-compatible file system hierarchy, including the root directory (/) and various standard directories, such as /home, /usr, and /var. These directories and their subdirectories contain the files and directories specific to the Linux environment.\nThe WSL 2 file system integration ensures that Linux processes can access and manipulate files stored on the Windows file system. This means you can work with files and directories in both the Linux and Windows environments seamlessly. For example, you can create, modify, and delete files from within WSL 2, and those changes will be reflected in the corresponding Windows directories and vice versa.\nWindows drives are mounted in the Linux /mnt/ directory. For instance, you can access Users folder a C:\\User\\ by running in WSL terminal:\ncd /mnt/c/Users/ Noting that accessing Windows files from Linux is considerably slower than using the native Linux file system. Where possible, create projects in the Linux file space, typically in your home folder (/home/\u0026lt;USERNAME\u0026gt; or ~).\nYou can also access WSL 2 files from the network path \\\\wsl$\\ in Windows\u0026rsquo;s File Explorer.\nCreate Linux symbolic link for Windows folder For ease of access, you can create a Linux symbolic link to any Windows folder from the terminal. For example, for C:\\projects\\:\ncd ~ ln -s /mnt/d/projects/ A projects folder will appear in your Linux home directory. Navigate to it using cd ~/project and you\u0026rsquo;ll actually be in /mnt/d/projects/, which maps directly to D:\\projects\\.\nMove or Clone Your WSL Linux Disk Image WSL Linux disk images are installed on your C: drive in deault. This may occupy a lot of space in the Windows\u0026rsquo;s system drive. Optionally, you can either move it to another drive to free up space on C:, or use the same image to create multiple Linux installations (which can be useful if you need different applications and setups for different projects - although Docker may be more practical).\nPresume that you are moving the Ubuntu Linux distro to D:\\wsl. In a Powershell terminal, then export Linux distro you want to move by name to a backup .tar file, such as D:\\backup\\ubuntu-22.04.tar.\nmkdir D:\\backup wsl --expoer Ubuntu-22.04 D:\\backup\\ubuntu-22.04.tar Then, unregister that distro to remove it by name from the C: drive.\nwsl --unregister Ubuntu-22.04 You can run wsl -l to verify the distro has been removed. Now, you can import the new WSL 2 distro at another location, such as D:\\wsl.\nmkdir D:\\wsl wsl --import Ubuntu-22.04 D:\\wsl\\ D:\\backup\\ubuntu-22.04.tar You can make any number of named clones from the same back-up by changing the name of distro after --import argument.\nAgain, verify the WSL distro has been successfully created by wsl -l command. At this point, Ubuntu will use root as the default user. To revert to your own account, run the following command:\nubuntu config --default-user \u0026lt;USERNAME\u0026gt; where \u0026lt;USERNAME\u0026gt; is the username you defined before.\nFor other distros that aren\u0026rsquo;t the WSL2 default distro, you need to log on to the distro and create/edit /etc/wsl.conf file.\nnano /etc/wsl.conf Add the following lines to the file\n[user] default=\u0026lt;USERNAME\u0026gt; Save the file, then restart the distro in PowerShell terminal.\nwsl --terminate \u0026lt;DISTRONAME\u0026gt; where \u0026lt;DISTRONAME\u0026gt; is the distro\u0026rsquo;s name you installed. Now you can feel free to delete backup file if you want.\nSave \u0026amp; Exit \u0026#34;nano\u0026#34; editor To save the file use Ctrl + S combination while Ctrl + X is use to exit the editor in terminal.\nVisual Studio Code with WSL 2 Integration Visual Studio Code (VS Code) permits you to use any Windows or Linux terminal. In VS Code, you need to install WSL extension (search in Extensions tab). The WSL extension enables you to run VS Code within the WSL.\nWhen the WSL extension si installed, you will see a new Remote Status bar item at the far left.\nThe Remote Status bar item can quickly show you in which context VS Code is running (local or remote).\nTo open new remote WSL window, you can press F1 to open Command Pallete in VS C and type WSL to select the option.\nConclusion Working with WSL 2 on Windows 11 offers an improved experience for running Linux applications. With WSL 2, you can seamlessly integrate Windows and Linux environments, allowing you to develop and execute code using Windows tools while leveraging the power of a Linux-based runtime. This integration simplifies web development, eliminates the need for virtual machines, and provides a more efficient workflow. Overall, WSL 2 on Windows 11 offers the benefits of both operating systems, enhancing productivity and making it easier to work with Linux applications on a Windows platform.\nReference Windows Subsystem for Linux Documentation. Windows Subsystem for Linux 2: The Complete Guide for Windows 10 \u0026amp; 11. Remote development in WSL. How to Create a Perfect Machine Learning Development Environment With WSL2 on Windows 10/11. ","permalink":"http://visionbike.github.io/posts/working-with-wsl2-on-windows11/","summary":"Windows Subsystem for Linux (WSL) is a compatibility layer provided by Microsoft that allows you to run a Linux environment directly on your Windows operating system. It enables you to execute Linux binaries, use Linux command-line tools, and access Linux file systems from within Windows.\nWhen it comes to machine learning (ML) development, WSL offers several advantages:\nLinux Compatibility: Many ML frameworks, libraries, and tools are primarily developed and optimized for Linux systems.","title":"Working With Windows Subsystem for Linux 2 on Windows 11"},{"content":"In this post, I will cover how to setup NVIDIA CUDA on Windows 11. To ensure a smooth setup process, it is crucial to follow the following steps:\nNVIDIA Drivers. Microsoft Visual Studio 2022 Community. NVIDIA CUDA Toolkit. NVIDIA cuDNN. TensorRT (optional). Miniforge (optional). 1. System Requirements To use CUDA, make sure your machine has a CUDA-capable GPU inside and the Microsoft Windows 11 should be updated 21H2 version.\nYou can verify if your machine has CUDA-supported GPU through Display Adapters section in the Windows Device Manager. Here you will find the vendor name and model of your GPU.\nYou also need to install Microsft Visual Studio 2022 Community as the native compilter for x86_64 application. The download link os the latest version is here and install the Desktop development with C++ workload.\nIf there is any NVIDIA CUDA Toolkit installed before, you need to uninstall before proceeding further, following these steps:\nOpen the Settings \u0026gt; Apps \u0026gt; Installed Apps. Scroll down and find NVIDIA CUDA applications. Click to \u0026ldquo;\u0026hellip;\u0026rdquo; button on the right and uninstall all NVIDIA GPU drivers and any associated software. Then you need to install NVIDIA driver to communicate your computer with NVIDIA devices. You can find the suitable driver from this website.\nAfter the installation is complete, reboot your system.\n2. Installing Mamba Mamba is a command-line interfacer (CLI) to manage conda\u0026rsquo;s environemts. For mamba configuration, please refer to conda documentation.\nFor the fresh installation, you can install Miniforge distribution \u0026gt;= Miniforge3-22.3.1.0. Miniforge comes with the popular conda-forge channel preconfigured, but you can modify the configuration to use any channel you like.\nInstallation\nFollow the instaltion prompts, taking note of options to Create start menu shortcuts and Add Miniforge3 to my PATH environment variable.\nAfter successful installation, you can use use the mamba commands as described in this user guide.\nPost-installation\nAfter installation, you make sure that the Anaconda is not the default configured channel, seeing this.\nDO NOT install anything into the base environment as this might break your installation. See here for details.\nThe most convenient way to use the Mamba will be via the Miniforge Prompt installed in the Start Menu.\n3. Installing NVIDIA CUDA Toolkit You can visit the NVIDIA Developer website for CUDA Toolkit TO get the latest version of NVIDIA CUDA Toolkit. For previous versions, you can check from the Archive of Previous CUDA Releases page.\nOn the dowload page, you choose the appropriate version based on your system.\nThen, you locate the downloaded installer file and double-click on it to start the installation process. Follow the on-screen instructions provided by the installer.\nOnce the installation is completed, you check environment variables CUDA_PATH and PATH to ensure that your system recognizes NVIDIA CUDA Toolkit.\nVerify CUDA Toolkit Installation You can verify the installation by running the following command in command prompt.\nnvcc --version If the installation was successful, you should see the CUDA version information displayed.\nnvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2024 NVIDIA Corporation Built on Tue_Feb_27_16:28:36_Pacific_Standard_Time_2024 Cuda compilation tools, release 12.4, V12.4.99 Build cuda_12.4.r12.4/compiler.33961263_0 It is important to verify that the NVIDIA CUDA Toolkit can find and communicate correctly with CUDA-compatible hardware. To do this, you need to compile and run some sample programs.\nCUDA samples are located in https://github.com/nvidia/cuda-samples. To use the samples, clone the project, build the samples in cyda-samples directory using MVSC 2022 compiler and run them following the instruction on the Github page.\nTo verify a correct configuration of the hardware and software, it is highly recommended that you build and run the deviceQuery sample program.\ndeviceQuery.exe If CUDA is installed and configured correctly, the output should look similar as below:\ndeviceQuery.exe Starting... CUDA Device Query (Runtime API) version (CUDART static linking) Detected 1 CUDA Capable device(s) Device 0: \u0026#34;NVIDIA GeForce RTX 3070 Ti Laptop GPU\u0026#34; CUDA Driver Version / Runtime Version 12.4 / 12.4 CUDA Capability Major/Minor version number: 8.6 Total amount of global memory: 8192 MBytes (8589410304 bytes) (046) Multiprocessors, (128) CUDA Cores/MP: 5888 CUDA Cores GPU Max Clock rate: 1410 MHz (1.41 GHz) Memory Clock rate: 7001 Mhz Memory Bus Width: 256-bit L2 Cache Size: 4194304 bytes Maximum Texture Dimension Size (x,y,z) 1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384) Maximum Layered 1D Texture Size, (num) layers 1D=(32768), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(32768, 32768), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total shared memory per multiprocessor: 102400 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 1536 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 1 copy engine(s) Run time limit on kernels: Yes Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement for Surfaces: Yes Device has ECC support: Disabled CUDA Device Driver Mode (TCC or WDDM): WDDM (Windows Display Driver Model) Device supports Unified Addressing (UVA): Yes Device supports Managed Memory: Yes Device supports Compute Preemption: Yes Supports Cooperative Kernel Launch: Yes Supports MultiDevice Co-op Kernel Launch: No Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0 Compute Mode: \u0026lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) \u0026gt; deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 12.4, CUDA Runtime Version = 12.4, NumDevs = 1 Result = PASS By running the bandwidthTest program, you can ensure that the system and CUDA-capable device are able to communicate correctly.\nbandwidthText.exe The output shoud be here.\n[CUDA Bandwidth Test] - Starting... Running on... Device 0: NVIDIA GeForce RTX 3070 Ti Laptop GPU Quick Mode Host to Device Bandwidth, 1 Device(s) PINNED Memory Transfers Transfer Size (Bytes) Bandwidth(GB/s) 32000000 11.3 Device to Host Bandwidth, 1 Device(s) PINNED Memory Transfers Transfer Size (Bytes) Bandwidth(GB/s) 32000000 13.9 Device to Device Bandwidth, 1 Device(s) PINNED Memory Transfers Transfer Size (Bytes) Bandwidth(GB/s) 32000000 361.1 Result = PASS NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled. To see a graphical representation, you can run the particles sample program.\nparticles.exe The installed NVIDIA CUDA Toolkit provides the necessary libraries, compilers, and tools for developing and running CUDA-accelerated applications and machine learning models.\n4. Installing NVIDIA cuDNN cuDNN (CUDA Deep Neural Network Library) is a GPU-accelerated library specifically designed and colaborated with NVIDA CUDA Toolkit to accelerate deep neural network computations. By utilizing cuDNN, deep learning frameworks can leverage the parallel processing capabilities of NVIDIA GPUs, leading to significant speed improvements in training and inference of deep neural networks.\nYou can visit NVIDIA Developer website for cuDNN for the latest version. You will need to register or log in to your NVIDIA Developer account in order to access the cuDNN download files. If you don\u0026rsquo;t have an account, you can create one for free.\nOnce you are logged in, choose the appropriate cuDNN version based on the NVIDIA CUDA Toolkit version and operating system. There are two main installation options:\nGraphical installation (executable): the graphical installer bundles the available per-CUDA cuDNN verions in one package. Tarball installation (zip): per-CUDA cuDNN versions are provided as saperate tarballs (zip). These .zip archives do not replace the graphical installer and are not meant for general consumption, as they are not installers. These zip archives can be found at this. Select one of two options for installing cuDNN. In this post, I will install cuDNN via the Tarball installation option.\nOnce download the zip archive, you unzip the cuDNN package.\nCopy the following files from the unzipped package into the NVIDIA cuDNN directory created by yourself.\nCopy bin\\cudnn*.h to C:Program Files\\NVIDIA\\CUDNN\\vx.y\\bin. Copy include\\cudnn*.h to C:\\Program Files\\NVIDIA\\CUDNN\\vx.y\\include. Copy lib\\x64\\cudnn*.lib to C:\\Program Files\\NVIDIA\\CUDNN\\vx.y\\lib. You must replace x.y with your specific cuDNN version.\nSet the environment variable to point to where cuDNN is located and add bin directory path to PATH environment variable.\nFor upgrading cuDNN, the remove the path to the directory containing cuDNN from PATH environment variable.\nVerify cuDNN Installation The cuDNN samples can be found here and download and extract the tar.xz archive.\nSince this is cross-platform LINUX samples, you need to install CMAKE and use it to compile the cuDNN samples.\nInside the cuda_sample_vx directory (x as the cuDNN version), make the comment to line 21 # add_subdirectory(mnistCUDNN).\nRun the following command in the command prompt.\nmkdir build \u0026amp;\u0026amp; cd build cmake -G \u0026#34;Visual Studio 17 2022\u0026#34; -D cuDNN_INCLUDE_DIR=\u0026#34;C:\\Program Files\\NVIDIA\\CUDNN\\v9.0\\include\u0026#34; -D cuDNN_LIBRARY_DIR=\u0026#34;C:\\Program Files\\NVIDIA\\CUDNN\\v9.0\\lib\u0026#34; .. cmake --build . --config Release By running the conv_sample program, you can ensure the cuDNN work in your system.\n.\\conv_sample\\Release\\conv_sample.exe The result should be as following:\nExecuting: conv_sample.exe Using format CUDNN_TENSOR_NCHW (for INT8x4 and INT8x32 tests use CUDNN_TENSOR_NCHW_VECT_C) Testing single precision ====USER DIMENSIONS==== input dims are 1, 32, 4, 4 filter dims are 32, 32, 1, 1 output dims are 1, 32, 4, 4 ====PADDING DIMENSIONS==== padded input dims are 1, 32, 4, 4 padded filter dims are 32, 32, 1, 1 padded output dims are 1, 32, 4, 4 Testing conv ^^^^ CUDA : elapsed = 0.0127218 sec, Test PASSED Testing half precision (math in single precision) ====USER DIMENSIONS==== input dims are 1, 32, 4, 4 filter dims are 32, 32, 1, 1 output dims are 1, 32, 4, 4 ====PADDING DIMENSIONS==== padded input dims are 1, 32, 4, 4 padded filter dims are 32, 32, 1, 1 padded output dims are 1, 32, 4, 4 Testing conv ^^^^ CUDA : elapsed = 0.0029165 sec, Test PASSED For Visual Studio project, add cuDNN by following steps:\nRight-click on the project name in Solution Explorer and choose **Properties. Click VC++ Directories and append C:\\Program Files\\NVIDIA\\CUDNN\\v9.x\\include to the Include Direcotries field. Click Linker \u0026gt; General and append C:\\Program Files\\NVIDIA\\CUDNN\\v9.x\\lib to the Additional Library Directories field. Click Linker \u0026gt; Input and append cudnn.h to the Additional Dependencies field and click OK. 5. Installing NVIDIA TensorRT (Optional) NVIDIA TensorRT is a C++ library that facilitates high-performance inference NVIDIA graphic processing units (GPUs). TensorRT takes a trained network, which consists of a network definition and a set of trained parameters, and produces a highly optimized runtime engine that performs inference for that network.\nTensorRT provides APIs via C++ and Python that help to express deep learning model via the Network Definition API or load a pre-defined model via the ONNX parser that allow TensorRT to optimize and run them on the NVIDIA GPU.\nTensorRT also include optional high speed mixed precision capabilities with difference NVIDIA architectures.\nYou can download the TensorRT at here. For Windows architecture, there is only zip archive installation.\nUnzip the zip archive and copy files in lib, include direcotries to C:\\Program Files\\NVIDIA\\TensorRT\\v10.0 directory created by yourself. Then, you add lib directory path to PATH environment variable.\nVerify TensorRT Installation Inside the zip archive also include the sample programs. To verify the installation is working, you should open a Visual Studio file from one of the samples, such as sampleOnnxMNIST.In the project, ensure that following is presented in the Visual Studio Solution project properties:\nAdd C:\\Program Files\\NVIDIA\\TensorRT\\v10.0\\lib to PATH and VC++ Directories \u0026gt; Executable Directories. Add C:\\Program Files\\NVIDIA\\TensorRT\\v10.0\\include to C/C++ \u0026gt; General \u0026gt; Additional Directories. Add nvinfer.lib and .lib files that that the projects requires to Linker \u0026gt; Input \u0026gt; Additional Dependencies. Compile the source code and run the example.\n.\\bin\\sample_onnx_mnist.exe The output should be as following:\n\u0026amp;\u0026amp;\u0026amp;\u0026amp; RUNNING TensorRT.sample_onnx_mnist [TensorRT v100000] # .\\sample_onnx_mnist.exe [04/08/2024-18:12:10] [I] Building and running a GPU inference engine for Onnx MNIST [04/08/2024-18:12:10] [I] [TRT] [MemUsageChange] Init CUDA: CPU +109, GPU +0, now: CPU 18227, GPU 1091 (MiB) [04/08/2024-18:12:18] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +2597, GPU +310, now: CPU 21109, GPU 1401 (MiB) [04/08/2024-18:12:18] [I] [TRT] ---------------------------------------------------------------- [04/08/2024-18:12:18] [I] [TRT] Input filename: ../data/mnist/mnist.onnx [04/08/2024-18:12:18] [I] [TRT] ONNX IR version: 0.0.3 [04/08/2024-18:12:18] [I] [TRT] Opset version: 8 [04/08/2024-18:12:18] [I] [TRT] Producer name: CNTK [04/08/2024-18:12:18] [I] [TRT] Producer version: 2.5.1 [04/08/2024-18:12:18] [I] [TRT] Domain: ai.cntk [04/08/2024-18:12:18] [I] [TRT] Model version: 1 [04/08/2024-18:12:18] [I] [TRT] Doc string: [04/08/2024-18:12:18] [I] [TRT] ---------------------------------------------------------------- [04/08/2024-18:12:18] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored. [04/08/2024-18:12:20] [I] [TRT] Detected 1 inputs and 1 output network tensors. [04/08/2024-18:12:20] [I] [TRT] Total Host Persistent Memory: 26400 [04/08/2024-18:12:20] [I] [TRT] Total Device Persistent Memory: 0 [04/08/2024-18:12:20] [I] [TRT] Total Scratch Memory: 0 [04/08/2024-18:12:20] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 6 steps to complete. [04/08/2024-18:12:20] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.8572ms to assign 3 blocks to 6 nodes requiring 32256 bytes. [04/08/2024-18:12:20] [I] [TRT] Total Activation Memory: 31744 [04/08/2024-18:12:20] [I] [TRT] Total Weights Memory: 26152 [04/08/2024-18:12:20] [I] [TRT] Engine generation completed in 1.68333 seconds. [04/08/2024-18:12:20] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 5 MiB [04/08/2024-18:12:20] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3036 MiB [04/08/2024-18:12:20] [I] [TRT] Loaded engine size: 0 MiB [04/08/2024-18:12:21] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB) [04/08/2024-18:12:21] [I] Input: [04/08/2024-18:12:21] [I] @@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@= ++++#++=*@@@@@ @@@@@@@@#. *@@@@@ @@@@@@@@= *@@@@@ @@@@@@@@. .. ...****%@@@@@ @@@@@@@@: .%@@#@@@@@@@@@@@@@ @@@@@@@% -@@@@@@@@@@@@@@@@@ @@@@@@@% -@@*@@@*@@@@@@@@@@ @@@@@@@# :#- ::. ::=@@@@@@@ @@@@@@@- -@@@@@@ @@@@@@%. *@@@@@ @@@@@@# :==*+== *@@@@@ @@@@@@%---%%@@@@@@@. *@@@@@ @@@@@@@@@@@@@@@@@@@+ *@@@@@ @@@@@@@@@@@@@@@@@@@= *@@@@@ @@@@@@@@@@@@@@@@@@* *@@@@@ @@@@@%+%@@@@@@@@%. .%@@@@@ @@@@@* .******= -@@@@@@@ @@@@@* .#@@@@@@@ @@@@@* =%@@@@@@@@ @@@@@@%#+++= =@@@@@@@@@@ @@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@@@@@@@@@@@@ [04/08/2024-18:12:21] [I] Output: [04/08/2024-18:12:21] [I] Prob 0 0.0000 Class 0: [04/08/2024-18:12:21] [I] Prob 1 0.0000 Class 1: [04/08/2024-18:12:21] [I] Prob 2 0.0000 Class 2: [04/08/2024-18:12:21] [I] Prob 3 0.0000 Class 3: [04/08/2024-18:12:21] [I] Prob 4 0.0000 Class 4: [04/08/2024-18:12:21] [I] Prob 5 1.0000 Class 5: ********** [04/08/2024-18:12:21] [I] Prob 6 0.0000 Class 6: [04/08/2024-18:12:21] [I] Prob 7 0.0000 Class 7: [04/08/2024-18:12:21] [I] Prob 8 0.0000 Class 8: [04/08/2024-18:12:21] [I] Prob 9 0.0000 Class 9: [04/08/2024-18:12:21] [I] \u0026amp;\u0026amp;\u0026amp;\u0026amp; PASSED TensorRT.sample_onnx_mnist [TensorRT v100000] # .\\sample_onnx_mnist.exe If you are using TensorRT Python API, make sure CUDA-Python is installed in your system or your virtual environment.\nInstalling from PyPI. pip install cuda-python Installing from Conda. conda install -c nvidia cuda-python Conda packages are assign a dependency to CUDA Toolkit: cuda-cudart (providing CUDA headers to enable writting NVRTC kernel with CUDA types) and cuda-nvrtc (providing NVTC shared library).\nThen you install TensorRT Python wheel.\npip install --pre --upgrade tensorrt Optional, install TensorRT lean and dispatch runtime wheels:\npip install tensorrt_lean tensorrt_dispatch To verify the installation is working, use python code.\nimport tensorrt print(tensorrt.__version__) assert(tensorrt.Builder(tensorrt.Logger())) Use a similar procedure to verify that the lean and dispatch modules work as expected.\nimport tensorrt_lean as trt print(trt.__version__) assert trt.Runtime(trt.Logger()) import tensorrt_dispatch as trt print(trt.__version__) assert trt.Runtime(trt.Logger()) Conclusion By following these steps and installing the required software, you will have an CUDA-ready environment in Windows 11 system for further machine learnin/deep learning applications. This environment will provide the necessary tools and libraries for GPU-accelerated computing and Python package management.\nReference CUDA Installation Guide for Microsoft Windows. Install CUDA and CUDNN on Windows \u0026amp; Linux. Installing Latest TensorFlow version with CUDA, cudNN and GPU support on Windows 11 PC. ","permalink":"http://visionbike.github.io/posts/setting-up-nvidia-cuda-on-windows-11/","summary":"In this post, I will cover how to setup NVIDIA CUDA on Windows 11. To ensure a smooth setup process, it is crucial to follow the following steps:\nNVIDIA Drivers. Microsoft Visual Studio 2022 Community. NVIDIA CUDA Toolkit. NVIDIA cuDNN. TensorRT (optional). Miniforge (optional). 1. System Requirements To use CUDA, make sure your machine has a CUDA-capable GPU inside and the Microsoft Windows 11 should be updated 21H2 version.\nYou can verify if your machine has CUDA-supported GPU through Display Adapters section in the Windows Device Manager.","title":"Setting Up NVIDIA CUDA on Windows 11"},{"content":"Creating a personal blog with technical content is a excellent way to enhance the writting skill, keep memorial notes and share personal experience with others. Ideally, these goals need to be achieved when creating and mantaining a blog:\nLow-cost - Free or as close to free as posisble. Productive - Easy to write and maintain. Cloud Native - Utilizes public cloud services for hosting, allowing for infinite scaling. After researching, I found that using Markdown, Hugo and GitHub Pages is indeed a powerful combination for creating and maintaining a cost-effective, productive, and cloud-native blog.\nMarkdown is markup language that is extremely easy to read, write natively and can be converted into HTML. Hugo is a static site generator written in the Go language that allows for content written in Markdown to be rendered into HTML webpages. GitHub Pages is the GitHub service that hosts web contentstored in a GitHub repository. In this post, I will show how to create an simple personal blog for FREE using above technologies. The blog was developed in Window Subsystem for Linux (WSL2).\nHere\u0026rsquo;s an outline of the steps you can follow to create the personal blog using these technologies:\n1. Setting up GitHub Account If you don\u0026rsquo;t have one already, creating a GitHub account. GitHub Pages allows you to host your blog for free using a GitHub repository.\n2. Installing Hugo Before starting, make sure git is installed in the local machine.\nsudo apt install -y git Configure Git with your username and email address.\ngit config --global user.name \u0026#34;Your Name\u0026#34; git config --global user.email \u0026#34;your.email@example.com\u0026#34; To verify that Git has been installed successfully, you can check the version using git --version. This command will display the installed version of Git.\nFor Ubuntu user, you can install Hugo on your host by this command:\nsudo apt install -y hugo Run the folloing command for verification:\nhugo version The Hugo version should be shown if the installation is successfull.\nhugo v0.92.2+extended linux/amd64 BuildDate=2023-01-31T11:11:57Z VendorInfo=ubuntu:0.92.2-1ubuntu0.1 3. Creating a new Hugo site You can run hugo new site command to create a new Hugo site:\nhugo new site \u0026lt;USERNAME\u0026gt;-hugo -f yml This command will set up the basic directory structure and configuration file in *.yml format for your blog.\nWhat is `\u0026lt;USERNAME\u0026gt;`?\nFor convenient management and organization, you should name the your blog project as above format with \u0026lt;USERNAME\u0026gt; as the your GitHub\u0026rsquo;s username, i.e., visionbike-hugo. It\u0026rsquo;s helpful to keep track your project and ensuring clarity when managing multiple repositories.\nThe site will be associated with a GitHub repository where you can store the source code of your blog. Hence, you need to initialize git in the local project for further use.\ncd \u0026amp;lt;USERNAME\u0026amp;gt;-hugo git init You also need to create a new repository on GitHub storage for your blog\u0026rsquo;s source code.\nCreating Github Repository Without README File\nBy creating a repository without a README file, you can avoid accidental history conflicts when pushing your local project to a fresh repository. You can always add a README file later if needed.\nNow, you link the local project to the GitHub repository by the git remote command:\ngit remote add origin https://github.com/\u0026lt;USERNAME\u0026gt;/\u0026lt;USERNAME\u0026gt;.github.io.git git banrch -M master By completing these steps, you have linked your local Hugo site to the GitHub repository. Now you can continue working on your site locally, commit any changes, and push them to the remote repository when ready.\n4. Installing Hugo Theme Installing a Hugo theme is a fantastic way to personalize your blog and enhance its visual appeal. You can access free Hugo themes via this website.\nFor my blog, I chose the PaperModX theme because of fonding its style and awesome features. I added its source code by the git submodule command.\ngit submodule add --depth 1 https://github.com/reorx/hugo-PaperModX themes/PaperModX The command will add the PaperModX theme repository as a submodule in the themes/PaperModX directory of your Hugo site.\nUpdating submodules\nIf you have already added the submodule before, you can run the following command to reclone it.\ngit submodule update --init --recursive For updating the theme, run this command.\ngit submodule update --remote --merge 5. Modify Hugo Configuration Once you have added the theme, you can configure it in your Hugo site\u0026rsquo;s configuration file (config.yml). Refer to the theme\u0026rsquo;s documentation for specific instructions on customization and configuration options. You will most likely want to modify the following fields:\nbaseURL: This should be set into the URL GitHub Pages for hosting your blog. If the GitHub repository is named \u0026lt;USERNAME\u0026gt;.github.io, then the value of baseURL will be https://\u0026lt;USERNAME\u0026gt;.github.io/. If the GitHub repository has any other name, then the value will be https://\u0026lt;USERNAME\u0026gt;.github.io/\u0026lt;REPOSITORY_NAME\u0026gt;/. For instance, my GitHub username is visionbike, then:\nIf the GitHub repository is named visionbike.github.io, then the baseURL will be https://visionbike.github.io/. If the GitHub repository is named visionbike-hugo, then the baseURL will be https://visionbike.github.io/visionbike-hugo/. title: This will be the title of your blog site as it appears at the top of a visitorâ€™s web browser when your site is open. It will also appear underneath your avatar, if one is present.\ntheme: The name of the theme Hugo should use to render your site. In my example, this will be set to PaperModX, since that is the name of the theme I am using.\nExample contents of the config.yml file can be found below.\nconfig.yml # base URL baseURL: \u0026#34;http://visionbike.github.io/\u0026#34; # site title title: \u0026#34;Visionbike - Personal Blog of CV | DSP | ML notes\u0026#34; # paginate paginate: 5 # theme config theme: \u0026#34;PaperModX\u0026#34; themesdir: \u0026#34;themes\u0026#34; # global config enableInlineShortcodes: true enableRobotsTXT: true buildDrafts: false buildFuture: false buildExpired: false enableEmoji: true # css minify for speeding up site minify: disableXML: true minifyOutput: true # site param config params: # environment env: \u0026#34;production\u0026#34; description: \u0026#34;Visionbike - Personal Blog of CV | DSP | ML notes\u0026#34; # color scheme: auto, dark, light defaultTheme: \u0026#34;dark\u0026#34; disableThemeToggle: true # header logo logo: text: \u0026#34;Visionbike\u0026#34; icon: \u0026#34;images/apple-touch-icon.png\u0026#34; iconHeight: 35 iconWidth: 35 # profile-mode profileMode: enabled: true title: \u0026#34;Phuc Thanh-Thien Nguyen\u0026#34; subtitle: \u0026#34;AI Researcher - Personal Blog of CV | DSP | ML notes\u0026#34; imageUrl: \u0026#34;images/avatar-real.png\u0026#34; imageTitle: \u0026#34;avatar-real\u0026#34; imageWidth: 180 imageHeight: 180 buttons: - name: Archives url: /archives/ - name: Tags url: /tags/ # home-info-mode homeInfoParams: title: \u0026#34;Phuc Thanh-Thien Nguyen\u0026#34; content: \u0026#34;AI Researcher - Personal Blog of CV | DSP | ML notes\u0026#34; # home social icons socialIcons: - name: github url: \u0026#34;https://github.com/visionbike/\u0026#34; - name: linkedIn url: \u0026#34;https://linkedin.com/in/nttphuc/\u0026#34; # post config author: \u0026#34;Visionbike\u0026#34; showCodeCopyButtons: true displayFullLangName: true showReadingTime: true showWordCount: true showPostNavLinks: true showBreadCrumbs: true enableImageZoom: true # assets images assets: # disableFingerprinting: true favicon: \u0026#34;images/favicon.ico\u0026#34; favicon16x16: \u0026#34;images/favicon-16x16.png\u0026#34; favicon32x32: \u0026#34;images/favicon-32x32.png\u0026#34; appleTouchIcon: \u0026#34;images/apple-touch-icon.png\u0026#34; safarPinnedTab: \u0026#34;images/safari-pinned-tab.svg\u0026#34; # search page fuseOpts: isCaseSensitive: false shouldSort: true location: 0 distance: 1000 threshold: 0.4 minMatchCharLength: 0 keys: [\u0026#34;title\u0026#34;, \u0026#34;permalink\u0026#34;, \u0026#34;summary\u0026#34;, \u0026#34;content\u0026#34;] # laguage config languages: en: weight: 1 # language code languageCode: \u0026#34;en\u0026#34; # determines default content language: \u0026#34;en\u0026#34;, \u0026#34;zh-cn\u0026#34;, \u0026#34;fr\u0026#34;, \u0026#34;vi\u0026#34;, ... defaultContentLanguage: \u0026#34;en\u0026#34; # menu language menu: main: - name: \u0026#34;Posts\u0026#34; weight: 1 url: \u0026#34;/posts/\u0026#34; - name: \u0026#34;Tags\u0026#34; url: \u0026#34;/tags/\u0026#34; weight: 3 - name: \u0026#34;Archive\u0026#34; url: \u0026#34;/archives/\u0026#34; weight: 4 - name: \u0026#34;Publish\u0026#34; url: \u0026#34;/publish/\u0026#34; weight: 5 - name: \u0026#34;About\u0026#34; weight: 10 url: \u0026#34;/about/\u0026#34; - name: \u0026#34;Search\u0026#34; weight: 100 url: \u0026#34;/search/\u0026#34; # for search page outputs: home: - HTML - RSS - JSON # syntax highlight pygmentsUseClasses: true pygmentsCodeFences: true markup: goldmark: renderer: unsafe: true highlight: lineNos: false codeFences: true noClasses: false After modifying the configuration file accordingly, you can commit and push changes from your local repository to GitHub.\ngit add config.yml git commit -m \u0026#34;modify configuration file\u0026#34; git push -u origin master 6. Creating New Hugo Post You are almost done finishing your personal blog!\nTo create the first post, you execute the hugo new command in the terminal.\nhugo new posts/first-post/index.md The command will create a new folder named first-post with new Markdown file index.md, inside the content/posts directory. Creating a new directory for each single post helps you manage your resource better when images, media sources can be store directly in this directory. The Markdown file will contain the template for your first blog post and you can start writing your content using Markdown syntax.\nThe contents of the first-post.md file will look like as:\nfirst-post.md\n--- title: \u0026#34;First Post\u0026#34; date: 2023-07-04T01:53:57+08:00 draft: true --- You need to add content to the Markdown file and update the metadata header. In the metadata header, you will find information such as the post\u0026rsquo;s title, publishing date and draft status. Change the value of the draft field from true to false to indicate that the post is ready to be published on your blog site. Your can also add other features supported by the installed theme for your post, i.e., comments, share buttons, navigation, etc.\nThe, you add the desired content to the body of the post. For instance, I added the line \u0026ldquo;This is my first post! Hello world!\u0026rdquo; at the bottom of the file. Feel free to customize the content to reflect your own thoughts and ideas in Markdown syntax.\nAfter modifying the first blog post, you can use git commit to commit and push the changes from your local repository to GitHub.\ngit add content/posts/first-post.md git commit -m \u0026#34;add the first post\u0026#34; git push -u origin master 7. Testing the Hugo Configuration Before hosting your blog to GitHub pages, make ensure Hugo can parse the configuration file and build our new blog post successfully.\nIn the local machine, you can run hugo server command to serve your site locally.\nhugo server --disableFastRender It will watch for any changes in your files and automatically rebuild your site whenever there are updates. Hugo will provide a local development server address, i.e., http://localhost:1313, where you can access your site locally.\nTo parse the configuration and build your site, you simply run hugo command.\nhugo If Hugo encounters any errors, they will be reported here. If the site is successfully built, then you will see output similar to the following.\nStart building sites â€¦ hugo v0.92.2+extended linux/amd64 BuildDate=2023-01-31T11:11:57Z VendorInfo=ubuntu:0.92.2-1ubuntu0.1 | EN -------------------+----- Pages | 13 Paginator pages | 0 Non-page files | 0 Static files | 18 Processed images | 0 Aliases | 0 Sitemaps | 1 Cleaned | 0 Total in 38 ms 8. Setting Up GitHub Actions Workflow Lastly, the GitHub Actions workflow has to be prepared for automatically building and deploying your blog to GitHub Pages. This workflow is defined by a YAML file in the .github/workflows directory structure at the root of the project.\nFirst, create the workflows folder.\nmkdir -p .github/workflows The command will create the .github/workflows directory if it doesn\u0026rsquo;t already exist. The -p option ensures that the parent directories are created if needed.\nThen, we create a new file within the created folder directory, named deploy_gh_pages.yaml with the following contents.\ndeploy_gh_pages.yaml\n--- --- name: Deploy Hugo site via GitHub Pages on: push: branches: - master # Set a branch to deploy pull_request: jobs: deploy: runs-on: ubuntu-22.04 permissions: contents: write concurrency: group: ${{ github.workflow }}-${{ github.ref }} steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;latest\u0026#34; extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 # If you\u0026#39;re changing the branch from main, # also change the `master` in `refs/heads/master` # below accordingly. if: github.ref == \u0026#39;refs/heads/master\u0026#39; with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public The YAML file sets up the deployment process using Hugo and GitHub Pages. The workflow is triggered on a push to the master branch, and it uses the specified actions to build and deploy your blog. You can find more in this.\nFinally, we use git commands to commit and push the changes from your local repository to GitHub.\ngit add .github/workflows/deploy_gh_pages.yaml git commit -m \u0026#34;Add GitHub Actions workflow\u0026#34; git push -u origin master 9. Configuring GitHub Pages The GitHub Pages will allow GitHub to build automatically and serve our website whenever changes are made to the underlying repository.\nFirst, we create new branch named gh-page. This branch will be used by GitHub Pages to build and serve your website. You can create the branch using the branch creation feature in your GitHub repository.\nThen, go to the Settings tab near the top of your repository.\nIn the left hand pane, locate and click on the Pages category.\nBy default, GitHub Pages will be disabled for your repository. To enable it, we need to select a branch for GitHub Pages to build and serve our website from. Under the Source section in the middle pane, you will see a dropdown menu labeled None. Click on the dropdown menu and select the gh-pages branch. This tells GitHub Pages to build and serve your website from the gh-pages branch.\nAfter selecting the deployment branch, you will see a notification indicating where your site will be published. It will provide you with a URL where your website can be accessed.\nWait for a few minutes to allow GitHub Pages to build and deploy your website. When the deployment completes, you can click on the URL provided in the notification to view your website. It may take some time for the changes to propagate and for your website to become accessible.\nConclusion Congratulations on setting up your blog using Hugo, Markdown, and GitHub Pages! This free and accessible solution enables you to create and share your technical knowledge with a wide audience. Happy blogging!\nReference How to Create a Simple, Free Blog with Hugo and GitHub Pages.\nhttps://github.com/reorx/hugo-PaperModX.\nhttps://gohugo.io/.\nhttps://github.com/olOwOlo/hugo-theme-even/.\n","permalink":"http://visionbike.github.io/posts/setting-up-personal-blog-with-hugo-and-gh-pages/","summary":"Creating a personal blog with technical content is a excellent way to enhance the writting skill, keep memorial notes and share personal experience with others. Ideally, these goals need to be achieved when creating and mantaining a blog:\nLow-cost - Free or as close to free as posisble. Productive - Easy to write and maintain. Cloud Native - Utilizes public cloud services for hosting, allowing for infinite scaling. After researching, I found that using Markdown, Hugo and GitHub Pages is indeed a powerful combination for creating and maintaining a cost-effective, productive, and cloud-native blog.","title":"Setting Up a Personal Blog With Hugo and GitHub Pages"},{"content":"I am Phuc Thanh-Thien Nguyen, current working as Ph.D Candidate at Autonomous and Soft Robotics (ASR) Laboratory, National Taiwan University, Taiwan. I focus on computer vision, digital signal processing, machine learning and deep learning in various applications.\nWelcome to my blog! In this blog, I will post small yet interesting notes of knowledge as well as state-of-the-art AI innovation, that I have found during my work as a researcher.\nI have done research on convolutional neural networks for computer-aided diagnosis and biosignal processing for various applications. In my current work, I am applying machine learning (supervised \u0026amp; unsupervised) and statistics to business problems. My go-to programming language is Python with the common data science and machine learning stack.\nCheck out my CV and connect with me on Linkedinâ€‹ if you want to get in touch.\nDisclaimer While I make every effort to ensure the information on this website is accurate and correct, I make no representations about the suitability of this content for any purposes.\nAbout Me! 1. Experience Research Assistant Applied Computing and Multimedia Lab, National Yang-Ming Chiao-Tung University, Taiwan, Sept 2020 - Jan 2021\nResearch suppervised and unsuppervised-based approaches for digital image enhancement. Software Engineer Lac Viet Computing Corporation, Vietnam, Sept 2017 - Aug 2018\nDevelop deep learning core of Question Answering System that using Restful API, and noSQL database (MongoDB) for Vietnamese Law.\nDevelop a prototype version for a facial recognition-based timekeeping service.\n2. Education Background National Taiwan University of Science and Technology Ph.D. Candidate, Electrical Engineering, 2021 - now\nStudy vision-based road anomaly detection, sEMG signal processing, and sEMG-based hand gesture recognition. National Taiwan University of Science and Technology M.Sc., Computer Science and Information Engineering, 2018 - 2020\nGPA: 4.11 / 4.3 Thesis: A Study on Optimal Chroma Subsampling and Upsampling Combination Methods for JPEG Image Reconstrsuction. Study small object detection and distance estimation for the ADAS system, chroma subsampling and upsampling in JPEG compression. VNU-HCM University of Science B.Sc., Computer Science, 2013 - 2017\nGPA: 3.36 / 4.0 Thesis: Spatial-Temporal Shape and Motion Feature for Dynamic Hand Gesture Recognition in Depth Video. ","permalink":"http://visionbike.github.io/about/","summary":"I am Phuc Thanh-Thien Nguyen, current working as Ph.D Candidate at Autonomous and Soft Robotics (ASR) Laboratory, National Taiwan University, Taiwan. I focus on computer vision, digital signal processing, machine learning and deep learning in various applications.\nWelcome to my blog! In this blog, I will post small yet interesting notes of knowledge as well as state-of-the-art AI innovation, that I have found during my work as a researcher.\nI have done research on convolutional neural networks for computer-aided diagnosis and biosignal processing for various applications.","title":"About"},{"content":"C.-H. Kuo, P. T.-T. Nguyen, and S.-L. Wu. Teaching Artificial Intelligence in Mechanical Engineering to Cultivate Cyber-physical System Talents. In Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2 (ITiCSE 2023). https://doi.org/10.1145/3587103.3594193\nI.W.D. Pranata, P.T.-T. Nguyen, K.-H. Su, Y.-C.Kuo, C.-H Kuo. Knee Angle Generation with Walking Speed Adaptation Ability for a Powered Transfemoral Prosthetic Leg Prototype. Inventions 2023, 8, 67. https://doi.org/10.3390/inventions8030067\nM.-H. Hsu; P.T.-T. Nguyen; D.-D. Nguyen; C.-H. Kuo. Image Servo Tracking of a Flexible Manipulator Prototype with Connected Continuum Kinematic Modules. Actuators 2022, 11, 360. DOI: https://doi.org/10.3390/act11120360\nT.-K. Nguyen, P.T.-T. Nguyen, D.-D.Nguyen, C.-H. Kuo. Effective Free-Driving Region Detection for Mobile Robots by Uncertainty Estimation Using RGB-D Data. Sensors 2022, 22, 4751. DOI: https://doi.org/10.3390/s22134751\nP.T.-T. Nguyen, S.-W. Yan, J.-F. Liao, C.-H. Kuo. Autonomous Mobile Robot Navigation in Sparse LiDAR Feature Environments. Appl. Sci. 2021, 11, 5963. DOI: https://doi.org/10.3390/app11135963\nA.-T. Nguyen, S.-H. Lu, P.T.-T. Nguyen. Validating and Forecasting Carbon Emissions in the Framework of the Environmental Kuznets Curve: The Case of Vietnam. Energies 2021, 14, 3144. DOI: https://doi.org/10.3390/en14113144\nVo Hoai Viet, Nguyen Thanh Thien Phuc, Pham Minh Hoang, Liu Kim Nghia, \u0026quot; Spatial-Temporal Shape and Motion Features for Dynamic Hand Gesture Recognition in Depth Video\u0026quot;, International Journal of Image, Graphics and Signal Processing(IJIGSP), Vol.10, No.9, pp. 17-26, 2018. DOI: http://doi.org/10.5815/ijigsp.2018.09.03\n","permalink":"http://visionbike.github.io/publish/","summary":"C.-H. Kuo, P. T.-T. Nguyen, and S.-L. Wu. Teaching Artificial Intelligence in Mechanical Engineering to Cultivate Cyber-physical System Talents. In Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2 (ITiCSE 2023). https://doi.org/10.1145/3587103.3594193\nI.W.D. Pranata, P.T.-T. Nguyen, K.-H. Su, Y.-C.Kuo, C.-H Kuo. Knee Angle Generation with Walking Speed Adaptation Ability for a Powered Transfemoral Prosthetic Leg Prototype. Inventions 2023, 8, 67. https://doi.org/10.3390/inventions8030067\nM.-H. Hsu; P.T.-T. Nguyen; D.","title":"Publish"}]