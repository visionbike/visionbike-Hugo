<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Visionbike - Personal Blog of CV | DSP | ML notes</title>
    <link>http://visionbike.github.io/</link>
    <description>Recent content on Visionbike - Personal Blog of CV | DSP | ML notes</description>
    <image>
      <url>http://visionbike.github.io/images/apple-touch-icon.png</url>
      <link>http://visionbike.github.io/images/apple-touch-icon.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 21 Aug 2023 14:57:01 +0800</lastBuildDate><atom:link href="http://visionbike.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Build OpenCV with CUDA on Windows 11</title>
      <link>http://visionbike.github.io/posts/build-opencv-cuda-on-windows/</link>
      <pubDate>Mon, 21 Aug 2023 14:57:01 +0800</pubDate>
      
      <guid>http://visionbike.github.io/posts/build-opencv-cuda-on-windows/</guid>
      <description>Since pre-built OpenCV binaries do not include CUDA modules, this post is a tutorial for building OpenCV with CUDA on Windows 11. The obvious dvantage of OpenCV CUDA is boosting performance of most functions, you can find evidence here.
1. Prerequisite There are a couples of softwares or libraries having been downloaded and installed before getting started:
  Install the Visual Studio Community 2022 and select Desktop development with C++ workload.</description>
      <content:encoded><![CDATA[<p>Since pre-built OpenCV binaries do not include CUDA modules, this post is a tutorial for building OpenCV with CUDA on Windows 11. The obvious dvantage of OpenCV CUDA is boosting performance of most functions, you can find evidence <a href="https://www.jamesbowley.co.uk/qmd/opencv_cuda_performance.html">here</a>.</p>
<h2 id="1-prerequisite">1. Prerequisite</h2>
<p>There are a couples of softwares or libraries having been downloaded and installed before getting started:</p>
<ol>
<li>
<p>Install the <a href="https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community">Visual Studio Community 2022</a> and select <strong>Desktop development with C++</strong> workload.</p>
</li>
<li>
<p>Download the sources for OpenCV from GitHub by cloning the repositories (<a href="https://github.com/opencv/opencv">opencv</a> and <a href="https://github.com/opencv/opencv_contrib">opencv_contrib</a>).</p>
</li>
</ol>
<p><img loading="lazy" src="/posts/build-opencv-cuda-on-windows/opencv-cuda-folder.png" type="" alt="OpenCV CUDA folder"  /></p>
<p>After downloading, you can indicate the OpenCV&rsquo;s version you want to. For the current version, you can run the following command in <strong>Command Prompt</strong> at OpenCV&rsquo;s repositories:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">git checkout tags/4.8.0
</code></pre></div><ol start="3">
<li>
<p>Install the latest stable version (not release candidate -rc) of <a href="https://cmake.org/download/">CMake</a>.</p>
</li>
<li>
<p>Install the latest version of <a href="https://developer.nvidia.com/cuda-downloads">NVIDIA CUDA Toolkit</a> and add PATH. You can follow this <a href="https://visionbike.github.io/posts/create-ml-development-environment-on-window11/">tutorial</a>.</p>
</li>
</ol>
<div class="admonition warning"><p class="admonition-title">The latest CUDA Toolkit version</p>
<p>At the time writting this post, the latest <strong>NVIDIA CUDA Toolkit version 12.2</strong> still makes somes error when building with <strong>OpenCV 4.8.0</strong>, like <code>error C2666: 'operator !=': overloaded functions have similar conversions</code>. Therefore, if meeting such problem, try installing older version.</p>
</div>
<ol start="5">
<li>
<p>Register an account and download the latest verson of <a href="https://developer.nvidia.com/rdp/cudnn-download">NVIDIA DNN CUDA backend</a> for the version of CUDA. Extract the downloaded <strong>.zip</strong> file and copy <strong>bin</strong>, <strong>include</strong> and <strong>lib</strong> directories to your CUDA installation directory, i.e., <code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\vxx.x</code>.</p>
</li>
<li>
<p>Register an account and download the latest version of <a href="https://developer.nvidia.com/nvidia-video-codec-sdk">NVIDIA VIdeo Codec SDK</a>. Extract the downloaded <strong>.zip</strong> file and copy the contents inside <strong>Interface</strong> and <strong>Lib</strong> to <strong>include</strong> and <strong>lib</strong> directories inside the CUDA installation directory.</p>
</li>
<li>
<p><strong>Optional</strong> - Download and install the latest version of <a href="https://gstreamer.freedesktop.org/download/#toolchain-compatibility-notes">Gstreamer</a>.</p>
</li>
<li>
<p>Download and install the lastest version of <a href="https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Windows-x86_64.exe">mambaforge</a> to call OpenCV CUDA routines from python.</p>
</li>
</ol>
<h2 id="2-create-virtual-environtment-from-mambaforge">2. Create virtual environtment from Mambaforge</h2>
<p>To bind OpenCV for python3 without any conflit package installation, you should create an new virtual environment for the installation.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">mamba create -n opencv-cuda <span class="nv">python</span><span class="o">=</span>3.10
</code></pre></div><p>Activate the created environment and install <strong>numpy</strong> package.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">mamba activate opencv-cuda
mamaba install numpy
</code></pre></div><h2 id="3-build-opencv-with-cmake">3. Build OpenCV with CMake</h2>
<h3 id="preparation">Preparation</h3>
<p>Create a <strong>build</strong> folder with your OpenCV extracted folders.</p>
<p><img loading="lazy" src="/posts/build-opencv-cuda-on-windows/opencv-cuda-folder.png" type="" alt="OpenCV CUDA folder"  /></p>
<p>Edit the prioeiry of Python3 installation in <code>OpenCVDetectPython.cmake</code> file inside <strong>opencv-x.x.x/cmake</strong> folder.</p>
<p><img loading="lazy" src="/posts/build-opencv-cuda-on-windows/python3-prior.png" type="" alt="Python3 Prior"  /></p>
<h3 id="build-gui-build-configuration">Build GUI Build Configuration</h3>
<p>Open Cmake GUI and provide the paths to the OpenCV and target build folders.</p>
<p><img loading="lazy" src="/posts/build-opencv-cuda-on-windows/cmake-build.png" type="" alt="CMake GUI"  /></p>
<p>Hit <strong>Configure</strong> and select <strong>x64</strong> for the <strong>Optional platform for generator</strong>, then hit <strong>finish</strong> to start the configuration.</p>
<p>Once the configuration is done, edit the following parameters:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>CMAKE_INSTALL_PREFIX</td>
<td>path of opencv <strong>installation</strong></td>
</tr>
<tr>
<td>ENABLE_FAST_MATH</td>
<td>âœ…</td>
</tr>
<tr>
<td>WITH_CUDA</td>
<td>âœ…</td>
</tr>
<tr>
<td>BUILD_opencv_world</td>
<td>âœ…</td>
</tr>
<tr>
<td>BUILD_opencv_python3</td>
<td>âœ…</td>
</tr>
<tr>
<td>OPENCV_DNN_CUDA</td>
<td>âœ…</td>
</tr>
<tr>
<td>OPENCV_EXTRA_MODULES_PATH</td>
<td>path of <strong>modules</strong> directory in <strong>opencv_contrib-x.x.x</strong></td>
</tr>
<tr>
<td>OPENCV_PYTHON3_VERSION</td>
<td>âœ…</td>
</tr>
<tr>
<td>PYTHON3_EXECUTABLE</td>
<td>path of python3 executable in virtual env, i.e., <strong>C:/Users/ntthi/mambaforge/envs/opencv-cuda/python.exe</strong></td>
</tr>
<tr>
<td>PYTHON3_INCLUDE_DIR</td>
<td>path of <strong>include</strong> folder in the virtual env, i.e., <strong>C:/Users/ntthi/mambaforge/envs/opencv-cuda/include</strong></td>
</tr>
<tr>
<td>PYTHON3_LIBRARY</td>
<td>path of <strong>.lib</strong> file in the virtual env, i.e., <strong>C:/Users/ntthi/mambaforge/envs/opencv-cuda/libs/python310.lib</strong></td>
</tr>
<tr>
<td>PYTHON3_NUMPY_INCLUDE_DIRS</td>
<td>path of <strong>numpy</strong> in the virtual env, i.e., <strong>C:/Users/ntthi/mambaforge/envs/opencv-cuda/Lib/site-pakages/numpy/core/include</strong></td>
</tr>
<tr>
<td>PYTHON3_PACKAGES_PATH</td>
<td>path of <strong>site-packages</strong> in the virtual env, i.e., <strong>C:/Users/ntthi/mambaforge/envs/opencv-cuda/Lib/site-pakages</strong></td>
</tr>
</tbody>
</table>
<p>Note that the path separator hase to be &ldquo;/&rdquo; , <em>not</em> &ldquo;&quot;.</p>
<p>Hit <strong>Configure again</strong> again and check edit more parameters:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>CUDA_FAST_MATH</td>
<td>âœ…</td>
</tr>
<tr>
<td>CUDA_ARCH_BIN</td>
<td>version of computing capability, i.e., <strong>8.6</strong></td>
</tr>
<tr>
<td>WITH_CUBLAS</td>
<td>âœ…</td>
</tr>
<tr>
<td>WITH_CUDNN</td>
<td>âœ…</td>
</tr>
<tr>
<td>WITH_CUFFT</td>
<td>âœ…</td>
</tr>
</tbody>
</table>
<p>The CUDA_ARCH_BIN corresponding to your GPU is the value found in the left column of the <a href="https://en.wikipedia.org/wiki/CUDA#GPUs_supported">GPU support table</a>. For instance, &ldquo;8.6&rdquo; fir the RTX 3070 Ti.</p>
<p>If you do not want to create shared lib and make sure the opencv python libraries is installed, edit the following parameters:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>BUILD_SHARED_LIBS</td>
<td>ðŸ”³</td>
</tr>
<tr>
<td>OPENCV_FORCE_PYTHON_LIBS</td>
<td>âœ…</td>
</tr>
</tbody>
</table>
<p>Hit <strong>Configure</strong> at the last time and then hit <strong>Generate</strong>.</p>
<h3 id="build-the-project-with-visual-studio">Build the project with Visual Studio</h3>
<p>Open project <code>OpenCV.sln</code> created in the build folder. Go to <strong>Tools &gt; Options&hellip;</strong>, then uncheck the last parameter in <strong>Projects and Solutions &gt; Web Projects</strong>.</p>
<p></p>
<p>This setting may help to prevent the <code>ImportError: DLL load failed while importing cv2: The specified module could not be found.</code> error.</p>
<p>To build the OpenCV project, change <strong>Debug</strong> mode to <strong>Release</strong>. In the solution explorer expand <strong>CMakeTargets</strong>, right-click <strong>ALL_BUILD</strong> and select Build. This will take about an hour.</p>
<p><img loading="lazy" src="/posts/build-opencv-cuda-on-windows/build-opencv.png" type="" alt="OpenCV build"  /></p>
<p>Then repeat the step for <strong>INSTALL</strong> (below <strong>ALL_BUILD</strong>). Check for error in the two building steps. If everything is fine, you are done.</p>
<h3 id="check-installation-and-troubleshooting">Check Installation and Troubleshooting</h3>
<p>To verify the Python installation, activate the virtual environment for OpenCV install and try this code:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">cv2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">getCudaEnabledDeviceCount</span><span class="p">())</span>
</code></pre></div><p>If it works, congratulations you are good to go!</p>
<p>If you meets the problem <code>ImportError: DLL load failed while importing cv2: The specified module could not be found.</code>, it may lack the library&rsquo;s binaries. One solution is to edit <strong>config.py</strong> in <strong>C:/Users/ntthi/mambaforge/envs/opencv-cuda/Lib/site-packages/cv2</strong>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>

<span class="n">BINARIES_PATHS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;C:/opencv-cuda-4.8.0&#39;</span><span class="p">,</span> <span class="s1">&#39;x64/vc17/bin&#39;</span><span class="p">),</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;CUDA_PATH&#39;</span><span class="p">,</span> <span class="s1">&#39;C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.1&#39;</span><span class="p">),</span> <span class="s1">&#39;bin&#39;</span><span class="p">),</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;C:/gstreamer/1.0/msvc_x86_64&#39;</span><span class="p">,</span> <span class="s1">&#39;bin&#39;</span><span class="p">),</span>
<span class="p">]</span> <span class="o">+</span> <span class="n">BINARIES_PATHS</span>
</code></pre></div><p>These binary paths are from installed OpenCV, CUDA and Gstreamer (if installed).</p>
<p>For other bugs and problems, I refer you to the <a href="https://github.com/chrismeunier/OpenCV-CUDA-installation/blob/main/README.md">chrismeunier</a> and <a href="https://jamesbowley.co.uk/accelerate-opencv-4-4-0-build-with-cuda-and-python-bindings/#troubleshooting">Bowley</a>&rsquo;s troubleshooting tutorial.</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.jamesbowley.co.uk/qmd/opencv_cuda_python_windows.html">Build OpenCV (including Python) with CUDA on Windows</a>.</li>
<li><a href="https://github.com/chrismeunier/OpenCV-CUDA-installation/blob/main/README.md#opencv-cuda-installation">OpenCV CUDA installation</a>.</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Setting Up NVIDIA CUDA on Windows 11 With WSL 2</title>
      <link>http://visionbike.github.io/posts/create-ml-development-environment-on-windows11-with-wsl2/</link>
      <pubDate>Thu, 13 Jul 2023 16:44:33 +0800</pubDate>
      
      <guid>http://visionbike.github.io/posts/create-ml-development-environment-on-windows11-with-wsl2/</guid>
      <description>To get started with running CUDA on WSL, you need to instal NVIDIA Driver on Windows 11 with a compatible GeForce or NVIDIA RTX/Quadro card from this link.
Note that you only need to install NVIDIA Driver for Windows. Do not install any Linux Driver in WSL.
The latest NVIDIA Windows GPU Driver will fully support WSL 2. With CUDA support in the driver, existing applications compiled on a Linux system for the same target GPU can run unmodified within the WSL environment.</description>
      <content:encoded><![CDATA[<p>To get started with running CUDA on WSL, you need to instal NVIDIA Driver on Windows 11 with a compatible GeForce or NVIDIA RTX/Quadro card from this <a href="https://www.nvidia.com/Download/index.aspx">link</a>.</p>
<p>Note that you <strong>only need to install NVIDIA Driver for Windows. Do not install any Linux Driver in WSL</strong>.</p>
<p>The latest NVIDIA Windows GPU Driver will fully support WSL 2. With CUDA support in the driver, existing applications compiled on a Linux system for the same target GPU can run unmodified within the WSL environment. Once NVIDIA Windows GPU Driver is installed in the system, the CUDA driver will be stubbed inside the WSL 2 as <code>libcuda.so</code>. Therefore, you only use a separate CUDA Toolkit for WSL 2 which does not contain the NVIDIA Linux GPU Driver.</p>
<h2 id="1-install-nvidia-cuda-toolkit-for-wsl-2">1. Install NVIDIA CUDA Toolkit for WSL 2</h2>
<p>First remove the old GPG key from your WSL machine</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">sudo apt-key del 7fa2af80
</code></pre></div><p>Download <a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=WSL-Ubuntu&amp;target_version=2.0&amp;target_type=deb_local">CUDA Toolkit for WSL 2</a>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin
sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.2.1/local_installers/cuda-repo-wsl-ubuntu-12-2-local_12.2.1-1_amd64.deb
</code></pre></div><p>Then, folow the installation instruction.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">sudo dpkg -i cuda-repo-wsl-ubuntu-12-2-local_12.2.1-1_amd64.deb
sudo cp /var/cuda-repo-wsl-ubuntu-12-2-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda
</code></pre></div><p>Verify that CUDA is successfully installed by command</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">nvidia-smi
</code></pre></div><h2 id="2-install-nvidia-cudnn">2. Install NVIDIA CuDNN</h2>
<p>You can find the coresponding installation file from <a href="https://developer.nvidia.com/rdp/cudnn-archive">this</a>. Here you need to register and login to download it.</p>
<p><img loading="lazy" src="/posts/create-ml-development-environment-on-windows11-with-wsl2/cudnn-download.png" type="" alt="CuDNN download"  /></p>
<p>You can use Windows to download installation files then move to Ubuntu system in WSL 2. The WSL system is mapped to <code>\\wsl$\Ubuntu-22.04</code> and Windows drives are mounted under <code>/mnt</code> and can be accessed directly.</p>
<p>Once completed, it can be installed with following commands</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">sudo dpkg -i cudnn-local-repo-ubuntu2204-8.9.3.28_1.0-1_amd64.deb
sudo cp /var/cudnn-local-repo-ubuntu2204-8.9.3.28/cudnn-local-*-keyring.gpg /usr/share/keyrings/
sudo apt-get -y update
sudo apt-get -y upgrade
</code></pre></div><details class="admonition tip"><summary class="admonition-title">Fix &#34;libcuda.so.1 is not a symbolic link&#34; error</summary>
<p>Once the installattion is completed, you may receive the following error:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">/sbin/ldconfig.real: /usr/lib/wsl/lib/libcuda.so.1 is not a symbolic link
</code></pre></div><p>The reason may be the property of read-only of the directory. You can create other directory then link executable from <code>/usr/lib/wsl/lib/</code> to the new directory.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">cd</span> /usr/lib/wsl
sudo mkdir lib2
sudo ln -s lib/* lib2
sudo ldconfig
</code></pre></div><p>Then change <code>/usr/lib/wsl/lib</code> in the file <code>/etc/ld.so.conf.d/ld.wsl.conf</code> to <code>/usr/lib/wsl/lib2</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="c1"># This file was automatically generated by WSL. To stop automatic generation of this file, add the following entry to /etc/wsl.conf:</span>
<span class="c1">#[automount]</span>
<span class="c1">#ldconfig = false</span>
/usr/lib/wsl/lib2
</code></pre></div><p>Restarting WSL after setting will automatically restore, if you donâ€™t want to restore, you need to modif <code>/etc/wsl.conf</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>automount<span class="o">]</span>
<span class="nv">ldconfig</span> <span class="o">=</span> <span class="nb">false</span>
</code></pre></div></details>
<h2 id="3-set-up-python-environment-using-mambaforge">3. Set up Python environment using Mambaforge</h2>
<p>Python environment allows to manage separatelly different installations of Python and modules. It is useful when you have many projects running different version of Python and modules. It also help to manage installed modules for publish or reproduce.</p>
<p>There are different ways to create a python virtual environment, including built-in <code>venv</code>, <code>Conda</code> and <code>Anaconda</code>.</p>
<p><code>Conda</code> is a packaging tool and installer that aims to handle library dependencies outside of the Python packages as well as the Python packages themselves. For non preinstalled package manager, <code>Miniconda</code>, an installation of Conda, will be a good option.</p>
<p><code>Anacond</code>a is an installation of Conda that comes pre-loaded with a bunch of packages for scientific computing, i.e., <code>numpy</code>, <code>matplotlib</code>, <code>scipy</code>, etc. It also comes with IDE, Jupyter notebooks out of the box. This is helpful for beginers, but doesn&rsquo;t give much control.</p>
<p><code>Mamba</code> is a package manager which can be used with Python. Unlike <code>Conda</code>, it uses the C/C++ implementation to speed up the package installation. Read more about <code>mamba</code> in <a href="https://focalplane.biologists.com/2022/12/08/managing-scientific-python-environments-using-conda-mamba-and-friends/">here</a>. To install <code>mamba</code>, access <a href="https://github.com/conda-forge/miniforge">its repo</a> and pick the Mabaforge installer for your operating system.</p>
<p>Remember to run <code>conda init</code> at the end of your installation in your shell to activate the <code>mamba</code> command.</p>
<p><img loading="lazy" src="/posts/create-ml-development-environment-on-windows11-with-wsl2/mambaforge-install.png" type="" alt="Mambaforge install"  /></p>
<h3 id="create-and-use-virtual-environments">Create and use virtual environments</h3>
<p>The command using <code>mamba</code> is similar to the <code>conda</code> command.</p>
<ul>
<li>Create new environment</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">mamba create -n &lt;envname&gt; <span class="nv">python</span><span class="o">=</span>&lt;version&gt;
</code></pre></div><ul>
<li>Activate an environment</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">mamba activate &lt;envname&gt;
</code></pre></div><ul>
<li>Deactivate environment</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">mamba deactivate
</code></pre></div><ul>
<li>Delete an environment</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">mamba env remove -n &lt;envname&gt;
</code></pre></div><ul>
<li>Show all created environments</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">mamba env list
</code></pre></div><h3 id="working-with-python-packages">Working with Python packages</h3>
<p><strong>Remember to activate an environment first, do not install any packages in your base environment!</strong></p>
<ul>
<li>Install python packages</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">mamba install &lt;package&gt;<span class="o">[=</span>version<span class="o">]</span> <span class="o">[</span>-c &lt;channelname&gt;<span class="o">]</span>
</code></pre></div><p>When installing a package, you can optionally indicate specific additional channel that the packages are posted by community. <code>conda-forge</code> is one of most common additional channels.</p>
<ul>
<li>Delete packages</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">mamba remove &lt;package&gt;
</code></pre></div><ul>
<li>Show all installed packages in the virtual environment</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">mamba list <span class="o">[</span>-n &lt;envname&gt;<span class="o">]</span>
</code></pre></div><h2 id="reference">Reference</h2>
<ul>
<li><a href="https://medium.com/geekculture/install-cuda-and-cudnn-on-windows-linux-52d1501a8805">Install CUDA and CUDNN on Windows &amp; Linux</a>.</li>
<li><a href="https://docs.nvidia.com/cuda/wsl-user-guide/index.html">CUDA on WSL User Guide</a>.</li>
<li><a href="https://visualstudio.microsoft.com/free-developer-offers/">Machine learning environment build: WLS2+Ubuntu+CUDA+cuDNN</a>.</li>
<li><a href="https://biapol.github.io/blog/mara_lampert/getting_started_with_mambaforge_and_python/readme.html">Getting started with Mambaforge and Python</a>.</li>
<li><a href="https://ross-dobson.github.io/posts/2021/01/setting-up-python-virtual-environments-with-mambaforge/">Tutorial: Setting up Python enviroments with Mambaforge</a>.</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Working With Windows Subsystem for Linux 2 on Windows 11</title>
      <link>http://visionbike.github.io/posts/working-with-wsl2-on-windows11/</link>
      <pubDate>Thu, 13 Jul 2023 01:35:45 +0800</pubDate>
      
      <guid>http://visionbike.github.io/posts/working-with-wsl2-on-windows11/</guid>
      <description>Windows Subsystem for Linux (WSL) is a compatibility layer provided by Microsoft that allows you to run a Linux environment directly on your Windows operating system. It enables you to execute Linux binaries, use Linux command-line tools, and access Linux file systems from within Windows.
When it comes to machine learning (ML) development, WSL offers several advantages:
  Linux Compatibility: Many ML frameworks, libraries, and tools are primarily developed and optimized for Linux systems.</description>
      <content:encoded><![CDATA[<p><strong>Windows Subsystem for Linux (WSL)</strong> is a compatibility layer provided by Microsoft that allows you to run a Linux environment directly on your Windows operating system. It enables you to execute Linux binaries, use Linux command-line tools, and access Linux file systems from within Windows.</p>
<p>When it comes to machine learning (ML) development, WSL offers several advantages:</p>
<ol>
<li>
<p><strong>Linux Compatibility</strong>: Many ML frameworks, libraries, and tools are primarily developed and optimized for Linux systems. By using WSL, you can seamlessly run Linux-specific ML software on your Windows machine without the need for dual-booting or setting up a separate Linux machine.</p>
</li>
<li>
<p><strong>Access to Linux Packages</strong>: WSL provides access to the extensive collection of Linux packages available in various package managers (e.g., APT, YUM, and others). This allows you to easily install and manage Linux dependencies required for your ML projects.</p>
</li>
<li>
<p><strong>Command-Line Tools and Scripts</strong>: ML development often involves working with command-line tools and executing scripts. WSL provides a Linux shell environment, enabling you to run Linux commands and scripts directly on your Windows machine. This ensures compatibility and smooth execution of ML workflows that rely on Linux-specific commands and scripts.</p>
</li>
<li>
<p><strong>Compatibility with Docker</strong>: Docker is widely used in ML development to create isolated environments for running ML applications. WSL provides a seamless integration with Docker, allowing you to run Linux-based Docker containers on your Windows machine without any performance overhead.</p>
</li>
<li>
<p><strong>Consistency across Development Environments</strong>: If you work in a team where some members use Linux for ML development, using WSL allows you to maintain consistency across different development environments. It ensures that code, scripts, and configurations work consistently regardless of the underlying operating system.</p>
</li>
</ol>
<p>By utilizing WSL, you can leverage the power of Linux for ML development while enjoying the convenience of working within the Windows environment. It bridges the gap between Windows and Linux, making it easier to set up and manage a Linux-based ML environment on your Windows machine.</p>
<p>It is important to note that WSL is available in different versions, such as WSL 1 and WSL 2. WSL 2 offers enhanced performance and better integration with the Windows system, making it the recommended choice for ML development. The WSL 2 is fully integrated in Windows 10 build 19041 or Windows 11, so you may consider upgrade your system before install it.</p>
<div class="admonition tip"><p class="admonition-title">Check Windows Version</p>
<p>You can check Window version by going to <strong>Settings &gt; System &gt; About</strong> and scroll down to <strong>Windows specifications</strong>.</p>
</div>
<p>If you plan to work with Linux-based ML frameworks, libraries, or tools, using WSL can significantly streamline your development workflow and ensure compatibility with the wider ML community.</p>
<h2 id="1-pc-requirements">1. PC Requirements</h2>
<p>WSL 2 uses <strong>Hyper-V</strong> which requires harware virtualization support enabled in your BIOS. To ensure the hardware virtualization is available on your device, you can check by rebooting, pressing <code>DEL</code>, <code>F2</code> or <code>F10</code> (depending on the hardware manufacture) to open the BIOS pannels. Lokking for <strong>Virtualization Technology</strong>, <strong>VTx</strong>, <strong>Secure Virtual Machine (SVM)</strong> or similar options and ensure these options enabled, then reboot the machine.</p>
<details class="admonition info"><summary class="admonition-title">Disable Fast Start-up (Optional)</summary>
<p>Fast start-up saves Windows session and device drivers to a file so the next boot become faster. However, this can cause problems for Linux kernel, which may unresponsive on the next boost. If you encounter this problem, you can disable tthe fast start-up option by <strong>Control Panel &gt; Power Options &gt; Choose what the power buttons do &gt; Change settings that are currently unavailable</strong></p>
<p><img loading="lazy" src="/posts/working-with-wsl2-on-windows11/power-option.png" type="" alt="Power options"  /></p>
</details>
<h2 id="2-install-docker-desktop">2. Install Docker Desktop</h2>
<p><strong>Docker Desktop</strong> with WSL 2 provides an efficient and seamless integration between Docker containers and the WSL 2 environment. This combination allows you to run Linux containers directly on your Windows system, leveraging the power of WSL 2.</p>
<p>If you haven&rsquo;t installed Docker Desktop yet, please download and install the Docker Desktop for Windows from the <a href="https://www.docker.com/products/docker-desktop/">Docker website</a>. Installing Docker Desktop on Windows enables docker and docker-compose in both Windows and WSL 2.</p>
<p>Docker Desktop suggests you use WSL 2 when it&rsquo;s first launched. Alternatively, you can select <strong>Settings</strong> from the Docker system tray icon menu, then choose the <strong>General</strong> tab, check <strong>Use the WSL 2 based engine</strong>, and hit <strong>Apply &amp; Restart</strong>. Docker uses the default Linux distro, but you can also enable it in other installed distros from the <strong>WSL Integration</strong> panel in <strong>Settings</strong>, then <strong>Resources</strong>.</p>
<p><img loading="lazy" src="/posts/working-with-wsl2-on-windows11/docker-setting.png" type="" alt="Docker Settings"  /></p>
<p>Once Docker Desktop is installed, you can verify that it is running correctly by following command from <code>PowerShell</code> or <code>Command Prompt</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">docker</span> <span class="nf">version</span>
</code></pre></div><p>This command displays the Docker version and confirms that Docker is running with WSL 2 integration.</p>
<p>By combining Docker Desktop with WSL 2, you can take advantage of the containerization capabilities of Docker while benefiting from the compatibility and performance enhancements of WSL 2. It allows for efficient development and deployment of applications in a Linux environment, even if you&rsquo;re working on a Windows system.</p>
<h2 id="3-install-windows-terminal">3. Install Windows Terminal</h2>
<p><strong>Windows Terminal</strong> is a powerful and customizable terminal application for Windows that provides a modern and feature-rich command-line experience.  It allows you to interact with various shells and command-line tools in a single window, making it convenient for developers and system administrators. It is available from the <strong>Microsoft Store</strong> or it repository at <a href="github.com/microsoft/terminal/">github.com/microsoft/terminal/</a>.</p>
<p>Windows Terminal automatically adds WSL 2 Linux distros when they&rsquo;re installed and offers a configurable range of options including tabs, split views, themes, transparency, and key bindings.</p>
<h2 id="4-install-windows-subsystem-for-linux-2-wsl-2">4. Install Windows Subsystem for Linux 2 (WSL 2)</h2>
<p>To display a list of available WSL Linux distros, you can run followinf command in <code>PowerShell</code> in <strong>adminitror mode</strong>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">wsl</span> <span class="nf">--list</span> <span class="nf">--online</span>
</code></pre></div><p>To install the default Ubuntu distro (the latest version), run:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">wsl</span> <span class="nf">--install</span>
</code></pre></div><p>If you want to install a specific distro by name, such as <code>Ubuntu-22.04</code>, run:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">wsl</span> <span class="nf">--install</span> <span class="nf">-d</span> <span class="nf">Ubuntu-22.04</span>
</code></pre></div><details class="admonition tip"><summary class="admonition-title">Install WSL Distros from Microsoft Store</summary>
<p>Alternaltively, you can install Linux distro from the <strong>Microsoft Store</strong>.</p>
<p><img loading="lazy" src="/posts/working-with-wsl2-on-windows11/ms-store-wsl-distros.png" type="" alt="Miscroft Store WSL Linux Distros"  /></p>
</details>
<p>Once the installation is done, you will be prompted to enter a username and password. These are the credentials for Linux administration and completely separately from your Windows username.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">Please create a default UNIX user account. The username does not need to match your Windows username.
For more information visit: https://aka.ms/wslusers
Enter new UNIX username: Visionbike
New password:
Retype new password:
paddwd: password updated successfully
Installation successful!
</code></pre></div><p>Linux will eventually be ready and your terminal will show content similar to:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">To run a <span class="nb">command</span> as administrator <span class="o">(</span>user <span class="s2">&#34;root&#34;</span><span class="o">)</span>, use <span class="s2">&#34;sudo &lt;command&gt;&#34;</span>.
See <span class="s2">&#34;man sudo_root&#34;</span> <span class="k">for</span> details.

Welcome to Ubuntu 22.04.2 LTS <span class="o">(</span>GNU/Linux 5.15.90.1-microsoft-standard-WSL2 x86_64<span class="o">)</span>

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

 * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s
   just raised the bar <span class="k">for</span> easy, resilient and secure K8s cluster deployment.

   https://ubuntu.com/engage/secure-kubernetes-at-the-edge

This message is shown once a day. To disable it please create the
/home/visionbike/.hushlogin file.
</code></pre></div><p>For the first start, we should to install several Linux updates. The process will depend on the speed of the internet, so be patient if it slow!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">sudo apt update <span class="o">&amp;&amp;</span> sudo apt upgrade
</code></pre></div><p>You can also to check for Linux kernel updates from <code>PowerShell</code> running:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">wsl</span> <span class="nf">--update</span>
</code></pre></div><div class="admonition tip"><p class="admonition-title">Verify WSL 2 Installation</p>
<p>To check if the installation was successful, you can run the following command in <code>PowerShell</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">wsl</span> <span class="nf">-l</span> <span class="nf">-v</span>
  <span class="nf">NAME</span>                   <span class="nf">STATE</span>           <span class="nf">VERSION</span>
<span class="nf">*</span> <span class="nf">Ubuntu-22.04</span>           <span class="nf">Running</span>         <span class="mf">2</span>
  <span class="nf">docker-desktop</span>         <span class="nf">Stopped</span>         <span class="mf">2</span>
  <span class="nf">docker-desktop-data</span>    <span class="nf">Stopped</span>         <span class="mf">2</span>
</code></pre></div></div>
<h2 id="5-working-with-wsl-2">5. Working with WSL 2</h2>
<h3 id="set-a-default-linux-distribution">Set a Default Linux Distribution</h3>
<p>If you have more than one WSL Linu distro, you need to set the most frequent used distro as a default one. To set the default distro, run the following command in <strong>PowerShell</strong> temrinal.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">wsl</span> <span class="nf">--setdefault</span> <span class="p">&lt;</span><span class="nf">DISTRONAME</span><span class="p">&gt;</span>
</code></pre></div><p>where <code>&lt;DISTRONAME&gt;</code> is the distro&rsquo;s name you installed.</p>
<h3 id="file-system-in-wls-2">File System in WLS 2</h3>
<p>In WSL 2, the Linux file system is located within the WSL 2 virtual machine. It provides a Linux-compatible file system hierarchy, including the root directory (<code>/</code>) and various standard directories, such as <code>/home</code>, <code>/usr</code>, and <code>/var</code>. These directories and their subdirectories contain the files and directories specific to the Linux environment.</p>
<p>The WSL 2 file system integration ensures that Linux processes can access and manipulate files stored on the Windows file system. This means you can work with files and directories in both the Linux and Windows environments seamlessly. For example, you can create, modify, and delete files from within WSL 2, and those changes will be reflected in the corresponding Windows directories and vice versa.</p>
<p>Windows drives are mounted in the Linux <code>/mnt/</code> directory. For instance, you can access <code>Users</code> folder a <code>C:\User\</code> by running in WSL terminal:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">cd</span> /mnt/c/Users/
</code></pre></div><p>Noting that accessing Windows files from Linux is considerably slower than using the native Linux file system. Where possible, create projects in the Linux file space, typically in your home folder (<code>/home/&lt;USERNAME&gt;</code> or <code>~</code>).</p>
<p>You can also access WSL 2 files from the network path <code>\\wsl$\</code> in Windows&rsquo;s <strong>File Explorer</strong>.</p>
<p><img loading="lazy" src="/posts/working-with-wsl2-on-windows11/file-explorer.png" type="" alt="File Explorer"  /></p>
<details class="admonition tip"><summary class="admonition-title">Create Linux symbolic link for Windows folder</summary>
<p>For ease of access, you can create a Linux symbolic link to any Windows folder from the terminal. For example, for <code>C:\projects\</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">cd</span> ~
ln -s /mnt/d/projects/
</code></pre></div><p>A <code>projects</code> folder will appear in your Linux home directory. Navigate to it using cd <code>~/project</code> and you&rsquo;ll actually be in <code>/mnt/d/projects/</code>, which maps directly to <code>D:\projects\</code>.</p>
</details>
<h3 id="move-or-clone-your-wsl-linux-disk-image">Move or Clone Your WSL Linux Disk Image</h3>
<p>WSL Linux disk images are installed on your <code>C:</code> drive in deault. This may occupy a lot of space in the Windows&rsquo;s system drive. Optionally, you can either move it to another drive to free up space on <code>C:</code>, or use the same image to create multiple Linux installations (which can be useful <strong>if you need different applications and setups for different projects</strong> - although Docker may be more practical).</p>
<p>Presume that you are moving the Ubuntu Linux distro to <code>D:\wsl</code>. In a <strong>Powershell</strong> terminal, then export Linux distro you want to move by name to a backup <code>.tar</code> file, such as <code>D:\backup\ubuntu-22.04.tar</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">mkdir</span> <span class="nf">D:\backup</span>
<span class="nf">wsl</span> <span class="nf">--expoer</span> <span class="nf">Ubuntu-22.04</span> <span class="nf">D:\backup\ubuntu-22.04.tar</span>
</code></pre></div><p>Then, unregister that distro to remove it by name from the <code>C:</code> drive.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">wsl</span> <span class="nf">--unregister</span> <span class="nf">Ubuntu-22.04</span>
</code></pre></div><p>You can run <code>wsl -l</code> to verify the distro has been removed. Now, you can import the new WSL 2 distro at another location, such as <code>D:\wsl</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">mkdir</span> <span class="nf">D:\wsl</span>
<span class="nf">wsl</span> <span class="nf">--import</span> <span class="nf">Ubuntu-22.04</span> <span class="nf">D:\wsl\</span> <span class="nf">D:\backup\ubuntu-22.04.tar</span>
</code></pre></div><p>You can make any number of named clones from the same back-up by changing the name of distro after <code>--import</code> argument.</p>
<p>Again, verify the WSL distro has been successfully created by <code>wsl -l</code> command. At this point, Ubuntu will use root as the default user. To revert to your own account, run the following command:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">ubuntu</span> <span class="nf">config</span> <span class="nf">--default-user</span> <span class="p">&lt;</span><span class="nf">USERNAME</span><span class="p">&gt;</span>
</code></pre></div><p>where <code>&lt;USERNAME&gt;</code> is the username you defined before.</p>
<p>For other distros that aren&rsquo;t the WSL2 default distro, you need to log on to the distro and create/edit <code>/etc/wsl.conf</code> file.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">nano /etc/wsl.conf
</code></pre></div><p>Add the following lines to the file</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>user<span class="o">]</span>
<span class="nv">default</span><span class="o">=</span>&lt;USERNAME&gt;
</code></pre></div><p>Save the file, then restart the distro in <strong>PowerShell</strong> terminal.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-ps" data-lang="ps"><span class="nf">wsl</span> <span class="nf">--terminate</span> <span class="p">&lt;</span><span class="nf">DISTRONAME</span><span class="p">&gt;</span>
</code></pre></div><p>where <code>&lt;DISTRONAME&gt;</code> is the distro&rsquo;s name you installed. Now you can feel free to delete backup file if you want.</p>
<details class="admonition tip"><summary class="admonition-title">Save &amp; Exit &#34;nano&#34; editor</summary>
<p>To save the file use <code>Ctrl + S</code> combination while <code>Ctrl + X</code> is use to exit the editor in terminal.</p>
</details>
<h3 id="visual-studio-code-with-wsl-2-integration">Visual Studio Code with WSL 2 Integration</h3>
<p><a href="https://code.visualstudio.com/"><strong>Visual Studio Code (VS Code)</strong></a> permits you to use any Windows or Linux terminal. In VS Code, you need to install <strong>WSL</strong> extension (search in <strong>Extensions</strong> tab). The WSL extension enables you to run VS Code within the WSL.</p>
<p><img loading="lazy" src="/posts/working-with-wsl2-on-windows11/wsl-extension.png" type="" alt="WSL extension"  /></p>
<p>When the WSL extension si installed, you will see a new <strong>Remote Status</strong> bar item at the far left.</p>
<p><img loading="lazy" src="/posts/working-with-wsl2-on-windows11/remote-status.png" type="" alt="Remote status"  /></p>
<p>The Remote Status bar item can quickly show you in which context VS Code is running (local or remote).</p>
<p><img loading="lazy" src="/posts/working-with-wsl2-on-windows11/remote-status-activated.png" type="" alt="Remote status activated"  /></p>
<p>To open new remote WSL window, you can press <code>F1</code> to open <strong>Command Pallete</strong> in VS C and type <strong>WSL</strong> to select the option.</p>
<p><img loading="lazy" src="/posts/working-with-wsl2-on-windows11/connect-wsl.png" type="" alt="Connect WSL"  /></p>
<h2 id="conclusion">Conclusion</h2>
<p>Working with WSL 2 on Windows 11 offers an improved experience for running Linux applications. With WSL 2, you can seamlessly integrate Windows and Linux environments, allowing you to develop and execute code using Windows tools while leveraging the power of a Linux-based runtime. This integration simplifies web development, eliminates the need for virtual machines, and provides a more efficient workflow. Overall, WSL 2 on Windows 11 offers the benefits of both operating systems, enhancing productivity and making it easier to work with Linux applications on a Windows platform.</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://learn.microsoft.com/en-us/windows/wsl/">Windows Subsystem for Linux Documentation</a>.</li>
<li><a href="https://www.sitepoint.com/wsl2/">Windows Subsystem for Linux 2: The Complete Guide for Windows 10 &amp; 11</a>.</li>
<li><a href="https://code.visualstudio.com/docs/remote/wsl-tutorial">Remote development in WSL</a>.</li>
<li><a href="https://towardsdatascience.com/how-to-create-perfect-machine-learning-development-environment-with-wsl2-on-windows-10-11-2c80f8ea1f31">How to Create a Perfect Machine Learning Development Environment With WSL2 on Windows 10/11</a>.</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Setting Up NVIDIA CUDA on Windows 11</title>
      <link>http://visionbike.github.io/posts/setting-up-nvidia-cuda-on-windows-11/</link>
      <pubDate>Thu, 06 Jul 2023 12:41:36 +0800</pubDate>
      
      <guid>http://visionbike.github.io/posts/setting-up-nvidia-cuda-on-windows-11/</guid>
      <description>In this post, I will cover how to setup NVIDIA CUDA on Windows 11. To ensure a smooth setup process, it is crucial to follow the following steps:
 NVIDIA Drivers. Microsoft Visual Studio 2022 Community. NVIDIA CUDA Toolkit. NVIDIA cuDNN. TensorRT (optional). Miniforge (optional).  1. System Requirements To use CUDA, make sure your machine has a CUDA-capable GPU inside and the Microsoft Windows 11 should be updated 21H2 version.</description>
      <content:encoded><![CDATA[<p>In this post, I will cover how to setup <strong>NVIDIA CUDA</strong> on Windows 11. To ensure a smooth setup process, it is crucial to follow the following steps:</p>
<ul>
<li>NVIDIA Drivers.</li>
<li>Microsoft Visual Studio 2022 Community.</li>
<li>NVIDIA CUDA Toolkit.</li>
<li>NVIDIA cuDNN.</li>
<li>TensorRT (optional).</li>
<li>Miniforge (optional).</li>
</ul>
<h2 id="1-system-requirements">1. System Requirements</h2>
<p>To use CUDA, make sure your machine has a CUDA-capable GPU inside and the <strong>Microsoft Windows 11</strong> should be updated <strong>21H2</strong> version.</p>
<p>You can verify if your machine has CUDA-supported GPU through <strong>Display Adapters</strong> section in the <strong>Windows Device Manager</strong>. Here you will find the vendor name and model of your GPU.</p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/device-manager.png" type="" alt="device manager"  /></p>
<p>You also need to install <strong>Microsft Visual Studio 2022 Community</strong> as the native compilter for x86_64 application. The download link os the latest version is <a href="https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community"><strong>here</strong></a> and install the <strong>Desktop development with C++</strong> workload.</p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/visual-studio-installation.png" type="" alt="Visual Studio Installation"  /></p>
<p>If there is any NVIDIA CUDA Toolkit installed before, you need to uninstall before proceeding further, following these steps:</p>
<ol>
<li>Open the <strong>Settings &gt; Apps &gt; Installed Apps</strong>.</li>
<li>Scroll down and find NVIDIA CUDA applications.</li>
</ol>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-apps-list.png" type="" alt="NVIDIA apps list"  /></p>
<ol start="3">
<li>Click to &ldquo;&hellip;&rdquo; button on the right and uninstall all NVIDIA GPU drivers and any associated software.</li>
</ol>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-app-uninstallation.png" type="" alt="NVIDIA app uninstallation"  /></p>
<p>Then you need to install NVIDIA driver to communicate your computer with NVIDIA devices. You can find the suitable driver from this <a href="https://www.nvidia.com/download/index.aspx?lang=en-us"><strong>website</strong></a>.</p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-driver-installation.png" type="" alt="NVIDIA Driver Installation"  /></p>
<p>After the installation is complete, reboot your system.</p>
<h2 id="2-installing-mamba">2. Installing Mamba</h2>
<p><a href="https://mamba.readthedocs.io/en/latest/user_guide/mamba.html"><strong>Mamba</strong></a> is a command-line interfacer (CLI) to manage <code>conda</code>&rsquo;s environemts. For <code>mamba</code> configuration, please refer to <a href="https://conda.io/projects/conda/en/latest/user-guide/configuration/index.html"><strong>conda documentation</strong></a>.</p>
<p>For the fresh installation, you can install <a href="https://github.com/conda-forge/miniforge"><strong>Miniforge distribution</strong></a> &gt;= <code>Miniforge3-22.3.1.0</code>. <strong>Miniforge</strong> comes with the popular <code>conda-forge</code> channel preconfigured, but you can modify the configuration to use any channel you like.</p>
<div class="admonition note"><p class="admonition-title">Installation</p>
<p>Follow the instaltion prompts, taking note of options to <strong>Create start menu shortcuts</strong> and <strong>Add Miniforge3 to my PATH environment variable</strong>.</p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/miniforge-installation.png" type="" alt="Miniforge Installation"  /></p>
</div>
<p>After successful installation, you can use use the mamba commands as described in this <a href="https://mamba.readthedocs.io/en/latest/user_guide/mamba.html#mamba"><strong>user guide</strong></a>.</p>
<div class="admonition note"><p class="admonition-title">Post-installation</p>
<p>After installation, you make sure that the <strong>Anaconda</strong> is not the default configured channel, seeing <a href="https://mamba.readthedocs.io/en/latest/user_guide/troubleshooting.html#defaults-channels"><strong>this</strong></a>.</p>
<p><strong>DO NOT</strong> install anything into the <code>base</code> environment as this might break your installation. See <a href="https://mamba.readthedocs.io/en/latest/user_guide/troubleshooting.html#base-packages"><strong>here</strong></a> for details.</p>
</div>
<h2 id="3-installing-nvidia-cuda-toolkit">3. Installing NVIDIA CUDA Toolkit</h2>
<p>You can visit the <a href="https://developer.nvidia.com/cuda-downloads"><strong>NVIDIA Developer website for CUDA Toolkit</strong></a> TO get the latest version of NVIDIA CUDA Toolkit. For previous versions, you can check from the <a href="https://developer.nvidia.com/cuda-toolkit-archive"><strong>Archive of Previous CUDA Releases</strong></a> page.</p>
<p>On the dowload page, you choose the appropriate version based on your system.</p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cuda-toolkit-download-page.png" type="" alt="Download CUDA Toolkit"  /></p>
<p>Then, you locate the downloaded installer file and double-click on it to start the installation process. Follow the on-screen instructions provided by the installer.</p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cuda-toolkit-installation.png" type="" alt="NVIDIA CUDA Toolkit install"  /></p>
<p>Once the installation is completed, you check environment variables <code>CUDA_PATH</code> and <code>PATH</code> to ensure that your system recognizes <strong>NVIDIA CUDA Toolkit</strong>.</p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cuda-path-1.png" type="" alt="NVIDIA CUDA Path 1"  /></p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cuda-path-2.png" type="" alt="NVIDIA CUDA Path 2"  /></p>
<details class="admonition info"><summary class="admonition-title">Verify CUDA Toolkit Installation</summary>
<p>You can verify the installation by running the following command in command prompt.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">nvcc --version
</code></pre></div><p>If the installation was successful, you should see the CUDA version information displayed.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Tue_Feb_27_16:28:36_Pacific_Standard_Time_2024
Cuda compilation tools, release 12.4, V12.4.99
Build cuda_12.4.r12.4/compiler.33961263_0
</code></pre></div><p>It is important to verify that the <strong>NVIDIA CUDA Toolkit</strong> can find and communicate correctly with CUDA-compatible hardware. To do this, you need to compile and run some sample programs.</p>
<p>CUDA samples are located in <a href="https://github.com/nvidia/cuda-samples"><strong>https://github.com/nvidia/cuda-samples</strong></a>. To use the samples, clone the project, build the samples in <code>cyda-samples</code> directory using <strong>MVSC 2022 compiler</strong> and run them following the instruction on the Github page.</p>
<p>To verify a correct configuration of the hardware and software, it is highly recommended that you build and run the <code>deviceQuery</code> sample program.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">deviceQuery.exe
</code></pre></div><p>If  CUDA is installed and configured correctly, the output should look similar as below:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">deviceQuery.exe Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: <span class="s2">&#34;NVIDIA GeForce RTX 3070 Ti Laptop GPU&#34;</span>
  CUDA Driver Version / Runtime Version          12.4 / 12.4
  CUDA Capability Major/Minor version number:    8.6
  Total amount of global memory:                 8192 MBytes (8589410304 bytes)
  <span class="p">(</span>046<span class="p">)</span> Multiprocessors, (128) CUDA Cores/MP:    5888 CUDA Cores
  GPU Max Clock rate:                            1410 MHz (1.41 GHz)
  Memory Clock rate:                             7001 Mhz
  Memory Bus Width:                              256-bit
  L2 Cache Size:                                 4194304 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total shared memory per multiprocessor:        102400 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  1536
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
  Run time limit on kernels:                     Yes
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  CUDA Device Driver Mode (TCC or WDDM):         WDDM (Windows Display Driver Model)
  Device supports Unified Addressing (UVA):      Yes
  Device supports Managed Memory:                Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      No
  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0
  Compute Mode:
     <span class="p">&lt;</span> Default <span class="p">(</span>multiple host threads can use ::cudaSetDevice(<span class="p">)</span> with device simultaneously) &gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 12.4, CUDA Runtime Version = 12.4, NumDevs = 1
Result = PASS
</code></pre></div><p>By running the <code>bandwidthTest</code> program, you can ensure that the system and CUDA-capable device are able to communicate correctly.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">bandwidthText.exe
</code></pre></div><p>The output shoud be here.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">[CUDA Bandwidth Test] - Starting...
Running on...

 Device 0: NVIDIA GeForce RTX 3070 Ti Laptop GPU
 Quick Mode

 Host to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(GB/s)
   32000000                     11.3

 Device to Host Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(GB/s)
   32000000                     13.9

 Device to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(GB/s)
   32000000                     361.1

Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
</code></pre></div><p>To see a graphical representation, you can run the <code>particles</code> sample program.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">particles.exe
</code></pre></div><p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cuda-particle-sample.png" type="" alt="NVIDIA CUDA Particle Sample"  /></p>
</details>
<p>The installed <strong>NVIDIA CUDA Toolkit</strong> provides the necessary libraries, compilers, and tools for developing and running CUDA-accelerated applications and machine learning models.</p>
<h2 id="4-installing-nvidia-cudnn">4. Installing NVIDIA cuDNN</h2>
<p><strong>cuDNN (CUDA Deep Neural Network Library)</strong> is a GPU-accelerated library specifically designed and colaborated with <strong>NVIDA CUDA Toolkit</strong> to accelerate deep neural network computations. By utilizing <strong>cuDNN</strong>, deep learning frameworks can leverage the parallel processing capabilities of NVIDIA GPUs, leading to significant speed improvements in training and inference of deep neural networks.</p>
<p>You can visit <a href="https://developer.nvidia.com/rdp/cudnn-download"><strong>NVIDIA Developer website for cuDNN</strong></a> for the latest version. You will need to register or log in to your NVIDIA Developer account in order to access the cuDNN download files. If you don&rsquo;t have an account, you can create one for free.</p>
<p>Once you are logged in, choose the appropriate <strong>cuDNN</strong> version based on the <strong>NVIDIA CUDA Toolkit</strong> version and operating system. There are two main installation options:</p>
<ol>
<li><strong>Graphical installation</strong> (executable): the graphical installer bundles the available per-CUDA cuDNN verions in one package.</li>
<li><strong>Tarball installation</strong> (zip): per-CUDA cuDNN versions are provided as saperate tarballs (zip). These <code>.zip</code> archives do not replace the graphical installer and are not meant for general consumption, as they are not installers. These <code>zip</code> archives can be found at <a href="https://developer.download.nvidia.com/compute/cudnn/redist/cudnn/windows-x86_64/"><strong>this</strong></a>.</li>
</ol>
<p>Select one of two options for installing <strong>cuDNN</strong>. In this post, I will install <strong>cuDNN</strong> via the Tarball installation option.</p>
<p>Once download the <code>zip</code> archive, you unzip the <strong>cuDNN</strong> package.</p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cudnn-unzip.png" type="" alt="NVIDIA cuDNN Unzip"  /></p>
<p>Copy the following files from the unzipped package into the <strong>NVIDIA cuDNN</strong> directory created by yourself.</p>
<ul>
<li>Copy <code>bin\cudnn*.h</code> to <strong>C:Program Files\NVIDIA\CUDNN\vx.y\bin</strong>.</li>
<li>Copy <code>include\cudnn*.h</code> to <strong>C:\Program Files\NVIDIA\CUDNN\vx.y\include</strong>.</li>
<li>Copy <code>lib\x64\cudnn*.lib</code> to <strong>C:\Program Files\NVIDIA\CUDNN\vx.y\lib</strong>.</li>
</ul>
<p>You must replace <code>x.y</code> with your specific <strong>cuDNN</strong> version.</p>
<p>Set the environment variable to point to where <strong>cuDNN</strong> is located and add <code>bin</code> directory path to <code>PATH</code> environment variable.</p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cudnn-path.png" type="" alt="NVIDIA cuDNN Path"  /></p>
<p>For upgrading <strong>cuDNN</strong>, the remove the path to the directory containing <strong>cuDNN</strong> from <code>PATH</code> environment variable.</p>
<details class="admonition info"><summary class="admonition-title">Verify cuDNN Installation</summary>
<p>The <strong>cuDNN</strong> samples can be found <a href="https://developer.download.nvidia.com/compute/cudnn/redist/cudnn_samples/source/"><strong>here</strong></a> and download and extract the <code>tar.xz</code> archive.</p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cudnn-samples.png" type="" alt="NVIDIA cuDNN Samples"  /></p>
<p>Since this is cross-platform LINUX samples, you need to install <a href="https://cmake.org/download/"><strong>CMAKE</strong></a> and use it to compile the <strong>cuDNN</strong> samples.</p>
<p>Inside the <code>cuda_sample_vx</code> directory (<code>x</code> as the <strong>cuDNN</strong> version), make the comment to line 21 <code># add_subdirectory(mnistCUDNN)</code>.</p>
<p>Run the following command in the command prompt.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd"><span class="k">mkdir</span> build <span class="p">&amp;&amp;</span> <span class="k">cd</span> build
cmake -G <span class="s2">&#34;Visual Studio 17 2022&#34;</span> -D cuDNN_INCLUDE_DIR=<span class="s2">&#34;C:\Program Files\NVIDIA\CUDNN\v9.0\include&#34;</span> -D cuDNN_LIBRARY_DIR=<span class="s2">&#34;C:\Program Files\NVIDIA\CUDNN\v9.0\lib&#34;</span> ..
cmake --build . --config Release
</code></pre></div><p>By running the <code>conv_sample</code> program,  you can ensure the <strong>cuDNN</strong> work in your system.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">.\conv_sample\Release\conv_sample.exe
</code></pre></div><p>The result should be as following:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">Executing: conv_sample.exe
Using format CUDNN_TENSOR_NCHW (for INT8x4 and INT8x32 tests use CUDNN_TENSOR_NCHW_VECT_C)
Testing single precision
====USER DIMENSIONS====
input dims are 1, 32, 4, 4
filter dims are 32, 32, 1, 1
output dims are 1, 32, 4, 4
====PADDING DIMENSIONS====
padded input dims are 1, 32, 4, 4
padded filter dims are 32, 32, 1, 1
padded output dims are 1, 32, 4, 4
Testing conv
<span class="se">^^^^</span> CUDA : elapsed = 0.0127218 sec,
Test PASSED
Testing half precision (math in single precision)
====USER DIMENSIONS====
input dims are 1, 32, 4, 4
filter dims are 32, 32, 1, 1
output dims are 1, 32, 4, 4
====PADDING DIMENSIONS====
padded input dims are 1, 32, 4, 4
padded filter dims are 32, 32, 1, 1
padded output dims are 1, 32, 4, 4
Testing conv
<span class="se">^^^^</span> CUDA : elapsed = 0.0029165 sec,
Test PASSED
</code></pre></div></details>
<p>For <strong>Visual Studio</strong> project, add <strong>cuDNN</strong> by following steps:</p>
<ul>
<li>Right-click on the project name in <strong>Solution Explorer</strong> and choose **Properties.</li>
<li>Click <strong>VC++ Directories</strong> and append <code>C:\Program Files\NVIDIA\CUDNN\v9.x\include</code> to the <strong>Include Direcotries</strong> field.</li>
<li>Click <strong>Linker &gt; General</strong> and append <code>C:\Program Files\NVIDIA\CUDNN\v9.x\lib</code> to the <strong>Additional Library Directories</strong> field.</li>
<li>Click <strong>Linker &gt; Input</strong> and append <code>cudnn.h</code> to the <strong>Additional Dependencies</strong> field and click <strong>OK</strong>.</li>
</ul>
<h2 id="5-installing-nvidia-tensorrt-optional">5. Installing NVIDIA TensorRT (Optional)</h2>
<p><strong>NVIDIA TensorRT</strong> is a C++ library that facilitates high-performance inference NVIDIA graphic processing units (GPUs). <strong>TensorRT</strong> takes a trained network, which consists of a network definition and a set of trained parameters, and produces a highly optimized runtime engine that performs inference for that network.</p>
<p><strong>TensorRT</strong> provides APIs via C++ and Python that help to express deep learning model via the Network Definition API or load a pre-defined model via the ONNX parser that allow <strong>TensorRT</strong> to optimize and run them on the NVIDIA GPU.</p>
<p><strong>TensorRT</strong> also include optional high speed mixed precision capabilities with difference NVIDIA architectures.</p>
<p>You can download the <strong>TensorRT</strong> at <a href="https://developer.nvidia.com/tensorrt/download/10x"><strong>here</strong></a>. For Windows architecture, there is only <code>zip</code> archive installation.</p>
<p>Unzip the <code>zip</code> archive and copy files in <code>lib</code>, <code>include</code> direcotries to <strong>C:\Program Files\NVIDIA\TensorRT\v10.0</strong> directory created by yourself. Then, you add <code>lib</code> directory path to <code>PATH</code> environment variable.</p>
<p><img loading="lazy" src="/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-tensorrt-path.png" type="" alt="NVIDIA TensorRT Path"  /></p>
<details class="admonition info"><summary class="admonition-title">Verify TensorRT Installation</summary>
<p>Inside the <code>zip</code> archive also include the sample programs. To verify the installation is working, you should open a Visual Studio file from one of the samples, such as <code>sampleOnnxMNIST</code>.In the project, ensure that following is presented in the Visual Studio Solution project properties:</p>
<ul>
<li>Add <code>C:\Program Files\NVIDIA\TensorRT\v10.0\lib</code> to <code>PATH</code> and <strong>VC++ Directories &gt; Executable Directories</strong>.</li>
<li>Add <code>C:\Program Files\NVIDIA\TensorRT\v10.0\include</code> to <strong>C/C++ &gt; General &gt; Additional Directories</strong>.</li>
<li>Add <code>nvinfer.lib</code> and <code>.lib</code> files that that the projects requires to <strong>Linker &gt; Input &gt; Additional Dependencies</strong>.</li>
</ul>
<p>Compile the source code and run the example.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">.\bin\sample_onnx_mnist.exe
</code></pre></div><p>The output should be as following:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd"><span class="p">&amp;&amp;&amp;&amp;</span> RUNNING TensorRT.sample_onnx_mnist [TensorRT v100000] # .\sample_onnx_mnist.exe
[04/08/2024-18:12:10] [I] Building and running a GPU inference engine for Onnx MNIST
[04/08/2024-18:12:10] [I] [TRT] [MemUsageChange] Init CUDA: CPU +109, GPU +0, now: CPU 18227, GPU 1091 (MiB)
[04/08/2024-18:12:18] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +2597, GPU +310, now: CPU 21109, GPU 1401 (MiB)
[04/08/2024-18:12:18] [I] [TRT] ----------------------------------------------------------------
[04/08/2024-18:12:18] [I] [TRT] Input filename:   ../data/mnist/mnist.onnx
[04/08/2024-18:12:18] [I] [TRT] ONNX IR version:  0.0.3
[04/08/2024-18:12:18] [I] [TRT] Opset version:    8
[04/08/2024-18:12:18] [I] [TRT] Producer name:    CNTK
[04/08/2024-18:12:18] [I] [TRT] Producer version: 2.5.1
[04/08/2024-18:12:18] [I] [TRT] Domain:           ai.cntk
[04/08/2024-18:12:18] [I] [TRT] Model version:    1
[04/08/2024-18:12:18] [I] [TRT] Doc string:
[04/08/2024-18:12:18] [I] [TRT] ----------------------------------------------------------------
[04/08/2024-18:12:18] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/08/2024-18:12:20] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[04/08/2024-18:12:20] [I] [TRT] Total Host Persistent Memory: 26400
[04/08/2024-18:12:20] [I] [TRT] Total Device Persistent Memory: 0
[04/08/2024-18:12:20] [I] [TRT] Total Scratch Memory: 0
[04/08/2024-18:12:20] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 6 steps to complete.
[04/08/2024-18:12:20] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.8572ms to assign 3 blocks to 6 nodes requiring 32256 bytes.
[04/08/2024-18:12:20] [I] [TRT] Total Activation Memory: 31744
[04/08/2024-18:12:20] [I] [TRT] Total Weights Memory: 26152
[04/08/2024-18:12:20] [I] [TRT] Engine generation completed in 1.68333 seconds.
[04/08/2024-18:12:20] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 5 MiB
[04/08/2024-18:12:20] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3036 MiB
[04/08/2024-18:12:20] [I] [TRT] Loaded engine size: 0 MiB
[04/08/2024-18:12:21] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[04/08/2024-18:12:21] [I] Input:
[04/08/2024-18:12:21] [I] @@@@@@@@@@@@@@@@@@@@@@@@@@@@
<span class="p">@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class="p">@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class="p">@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class="p">@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class="p">@@@@@@@@@@</span>=   ++++#++=*@@@@@
<span class="p">@@@@@@@@</span>#.            *@@@@@
<span class="p">@@@@@@@@</span>=             *@@@@@
<span class="p">@@@@@@@@</span>.   .. ...****%@@@@@
<span class="p">@@@@@@@@</span>: .%@@#@@@@@@@@@@@@@
<span class="p">@@@@@@@</span>%  -@@@@@@@@@@@@@@@@@
<span class="p">@@@@@@@</span>%  -@@*@@@*@@@@@@@@@@
<span class="p">@@@@@@@</span>#  :#- ::. ::=@@@@@@@
<span class="p">@@@@@@@</span>-             -@@@@@@
<span class="p">@@@@@@</span>%.              *@@@@@
<span class="p">@@@@@@</span>#     :==*+==   *@@@@@
<span class="p">@@@@@@</span><span class="nv">%---%</span>%@@@@@@@.  *@@@@@
<span class="p">@@@@@@@@@@@@@@@@@@@</span>+  *@@@@@
<span class="p">@@@@@@@@@@@@@@@@@@@</span>=  *@@@@@
<span class="p">@@@@@@@@@@@@@@@@@@</span>*   *@@@@@
<span class="p">@@@@@</span><span class="nv">%+%</span>@@@@@@@@<span class="nv">%.   .%</span>@@@@@
<span class="p">@@@@@</span>*  .******=    -@@@@@@@
<span class="p">@@@@@</span>*             .#@@@@@@@
<span class="p">@@@@@</span>*            =%@@@@@@@@
<span class="p">@@@@@@</span>%#+++=     =@@@@@@@@@@
<span class="p">@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class="p">@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class="p">@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>

[04/08/2024-18:12:21] [I] Output:
[04/08/2024-18:12:21] [I]  Prob 0  0.0000 Class 0:
[04/08/2024-18:12:21] [I]  Prob 1  0.0000 Class 1:
[04/08/2024-18:12:21] [I]  Prob 2  0.0000 Class 2:
[04/08/2024-18:12:21] [I]  Prob 3  0.0000 Class 3:
[04/08/2024-18:12:21] [I]  Prob 4  0.0000 Class 4:
[04/08/2024-18:12:21] [I]  Prob 5  1.0000 Class 5: **********
[04/08/2024-18:12:21] [I]  Prob 6  0.0000 Class 6:
[04/08/2024-18:12:21] [I]  Prob 7  0.0000 Class 7:
[04/08/2024-18:12:21] [I]  Prob 8  0.0000 Class 8:
[04/08/2024-18:12:21] [I]  Prob 9  0.0000 Class 9:
[04/08/2024-18:12:21] [I]
<span class="p">&amp;&amp;&amp;&amp;</span> PASSED TensorRT.sample_onnx_mnist [TensorRT v100000] # .\sample_onnx_mnist.exe
</code></pre></div></details>
<p>If you are using <strong>TensorRT Python API</strong>, make sure <strong>CUDA-Python</strong> is installed in your system or your virtual environment.</p>
<ul>
<li>Installing from <strong>PyPI</strong>.</li>
</ul>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">pip install cuda-python
</code></pre></div><ul>
<li>Installing from <strong>Conda</strong>.</li>
</ul>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">conda install -c nvidia cuda-python
</code></pre></div><p>Conda packages are assign a dependency to CUDA Toolkit: <code>cuda-cudart</code> (providing CUDA headers to enable writting NVRTC kernel with CUDA types) and <code>cuda-nvrtc</code> (providing NVTC shared library).</p>
<p>Then you install <strong>TensorRT</strong> Python wheel.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">pip install --pre --upgrade tensorrt
</code></pre></div><p>Optional, install <strong>TensorRT</strong> lean and dispatch runtime wheels:</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-cmd" data-lang="cmd">pip install tensorrt_lean tensorrt_dispatch
</code></pre></div><p>To verify the installation is working, use python code.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorrt</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tensorrt</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">assert</span><span class="p">(</span><span class="n">tensorrt</span><span class="o">.</span><span class="n">Builder</span><span class="p">(</span><span class="n">tensorrt</span><span class="o">.</span><span class="n">Logger</span><span class="p">()))</span>
</code></pre></div><p>Use a similar procedure to verify that the lean and dispatch modules work as expected.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorrt_lean</span> <span class="k">as</span> <span class="nn">trt</span>
<span class="nb">print</span><span class="p">(</span><span class="n">trt</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">trt</span><span class="o">.</span><span class="n">Runtime</span><span class="p">(</span><span class="n">trt</span><span class="o">.</span><span class="n">Logger</span><span class="p">())</span>
</code></pre></div><div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorrt_dispatch</span> <span class="k">as</span> <span class="nn">trt</span>
<span class="nb">print</span><span class="p">(</span><span class="n">trt</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">trt</span><span class="o">.</span><span class="n">Runtime</span><span class="p">(</span><span class="n">trt</span><span class="o">.</span><span class="n">Logger</span><span class="p">())</span>
</code></pre></div><h2 id="conclusion">Conclusion</h2>
<p>By following these steps and installing the required software, you will have an CUDA-ready environment in Windows 11 system for further machine learnin/deep learning applications. This environment will provide the necessary tools and libraries for GPU-accelerated computing and Python package management.</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/">CUDA Installation Guide for Microsoft Windows</a>.</li>
<li><a href="https://medium.com/geekculture/install-cuda-and-cudnn-on-windows-linux-52d1501a8805">Install CUDA and CUDNN on Windows &amp; Linux</a>.</li>
<li><a href="https://medium.com/@Gunter-Pearson/installing-latest-tensorflow-version-with-cuda-cudnn-and-gpu-support-on-windows-11-pc-e41fac5c5795">Installing Latest TensorFlow version with CUDA, cudNN and GPU support on Windows 11 PC</a>.</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Setting Up a Personal Blog With Hugo and GitHub Pages</title>
      <link>http://visionbike.github.io/posts/setting-up-personal-blog-with-hugo-and-gh-pages/</link>
      <pubDate>Tue, 04 Jul 2023 01:53:57 +0800</pubDate>
      
      <guid>http://visionbike.github.io/posts/setting-up-personal-blog-with-hugo-and-gh-pages/</guid>
      <description>Creating a personal blog with technical content is a excellent way to enhance the writting skill, keep memorial notes and share personal experience with others. Ideally, these goals need to be achieved when creating and mantaining a blog:
 Low-cost - Free or as close to free as posisble. Productive - Easy to write and maintain. Cloud Native - Utilizes public cloud services for hosting, allowing for infinite scaling.  After researching, I found that using Markdown, Hugo and GitHub Pages is indeed a powerful combination for creating and maintaining a cost-effective, productive, and cloud-native blog.</description>
      <content:encoded><![CDATA[<p>Creating a personal blog with technical content is a excellent way to enhance the writting skill, keep memorial notes and share personal experience with others. Ideally, these goals need to be achieved when creating and mantaining a blog:</p>
<ol>
<li><strong>Low-cost</strong> - Free or as close to free as posisble.</li>
<li><strong>Productive</strong> - Easy to write and maintain.</li>
<li><strong>Cloud Native</strong> - Utilizes public cloud services for hosting, allowing for infinite scaling.</li>
</ol>
<p>After researching, I found that using <strong>Markdown</strong>,  <strong>Hugo</strong> and <strong>GitHub Pages</strong>  is indeed a powerful combination for creating and maintaining a cost-effective, productive, and cloud-native blog.</p>
<ul>
<li><a href="https://daringfireball.net/projects/markdown/"><strong>Markdown</strong></a> is markup language that is extremely easy to read, write natively and can be converted into HTML.</li>
<li><a href="https://gohugo.io/"><strong>Hugo</strong></a> is a static site generator written in the Go language that allows for content written in Markdown to be rendered into HTML webpages.</li>
<li><a href="https://pages.github.com/"><strong>GitHub Pages</strong></a> is the GitHub service that hosts web contentstored in a GitHub repository.</li>
</ul>
<p>In this post, I will show how to create an simple personal blog for FREE using above technologies. The blog was developed in Window Subsystem for Linux (WSL2).</p>
<p>Here&rsquo;s an outline of the steps you can follow to create the personal blog using these technologies:</p>
<h2 id="1-setting-up-github-account">1. Setting up GitHub Account</h2>
<p>If you don&rsquo;t have one already, creating a GitHub account. GitHub Pages allows you to host your blog for free using a GitHub repository.</p>
<h2 id="2-installing-hugo">2. Installing Hugo</h2>
<p>Before starting, make sure <code>git</code> is installed in the local machine.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">sudo apt install -y git
</code></pre></div><p>Configure Git with your <u><strong>username</strong></u> and <u><strong>email address</strong></u>.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">git config --global user.name <span class="s2">&#34;Your Name&#34;</span>
</code></pre></div><div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">git config --global user.email <span class="s2">&#34;your.email@example.com&#34;</span>
</code></pre></div><p>To verify that Git has been installed successfully, you can check the version using <code>git --version</code>. This command will display the installed version of Git.</p>
<p>For Ubuntu user, you can  install Hugo on your host by this command:</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">sudo apt install -y hugo
</code></pre></div><p>Run the folloing command for verification:</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">hugo version
</code></pre></div><p>The Hugo version should be shown if the installation is successfull.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">hugo v0.92.2+extended linux/amd64 <span class="nv">BuildDate</span><span class="o">=</span>2023-01-31T11:11:57Z <span class="nv">VendorInfo</span><span class="o">=</span>ubuntu:0.92.2-1ubuntu0.1
</code></pre></div><h2 id="3-creating-a-new-hugo-site">3. Creating a new Hugo site</h2>
<p>You can run <code>hugo new site</code> command to create a new Hugo site:</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">hugo new site &lt;USERNAME&gt;-hugo -f yml
</code></pre></div><p>This command will set up the basic directory structure and configuration file in <code>*.yml</code> format for your blog.</p>
<div class="admonition tip"><p class="admonition-title">What is `&lt;USERNAME&gt;`?</p>
<p>For convenient management and organization, you should name the your blog project as above format with <strong>&lt;USERNAME&gt;</strong> as the your GitHub&rsquo;s username, i.e., <code>visionbike-hugo</code>. It&rsquo;s helpful to keep track your project and ensuring clarity when managing multiple repositories.</p>
</div>
<p>The site will be associated with a GitHub repository where you can store the source code of your blog. Hence, you need to initialize <code>git</code> in the local project for further use.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">cd</span> <span class="p">&amp;</span>lt<span class="p">;</span>USERNAME<span class="p">&amp;</span>gt<span class="p">;</span>-hugo
git init
</code></pre></div><p>You also need to create a new repository on GitHub storage for your blog&rsquo;s source code.</p>
<p><img loading="lazy" src="/posts/setting-up-personal-blog-with-hugo-and-gh-pages/create-source-code-repo.png" type="" alt="Create source code repository"  /></p>
<div class="admonition tip"><p class="admonition-title">Creating Github Repository Without README File</p>
<p>By creating a repository without a <strong>README</strong> file, you can avoid accidental history conflicts when pushing your local project to a fresh repository. You can always add a <strong>README</strong> file later if needed.</p>
</div>
<p>Now, you link the local project to the GitHub repository by the <code>git remote</code> command:</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">git remote add origin https://github.com/&lt;USERNAME&gt;/&lt;USERNAME&gt;.github.io.git
git banrch -M master
</code></pre></div><p>By completing these steps, you have linked your local Hugo site to the GitHub repository. Now you can continue working on your site locally, commit any changes, and push them to the remote repository when ready.</p>
<h2 id="4-installing-hugo-theme">4. Installing Hugo Theme</h2>
<p>Installing a Hugo theme is a fantastic way to personalize your blog and enhance its visual appeal. You can access free Hugo themes via this <a href="https://themes.gohugo.io/"><strong>website</strong></a>.</p>
<p>For my blog, I chose the <a href="https://github.com/reorx/hugo-PaperModX"><strong>PaperModX</strong></a> theme because of fonding its style and awesome features. I added its source code by the <code>git submodule</code> command.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">git submodule add --depth <span class="m">1</span> https://github.com/reorx/hugo-PaperModX themes/PaperModX
</code></pre></div><p>The command will add the <code>PaperModX</code> theme repository as a submodule in the <u><strong>themes/PaperModX</strong></u> directory of your Hugo site.</p>
<div class="admonition tip"><p class="admonition-title">Updating submodules</p>
<p>If you have already added the submodule before, you can run the following command to reclone it.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">git submodule update --init --recursive
</code></pre></div><p>For updating the theme, run this command.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">git submodule update --remote --merge
</code></pre></div></div>
<h2 id="5-modify-hugo-configuration">5. Modify Hugo Configuration</h2>
<p>Once you have added the theme, you can configure it in your Hugo site&rsquo;s configuration file (<code>config.yml</code>). Refer to the theme&rsquo;s documentation for specific instructions on customization and configuration options. You will most likely want to modify the following fields:</p>
<ul>
<li>
<p><u><strong>baseURL</strong></u>: This should be set into the URL GitHub Pages for hosting your blog. If the GitHub repository is named <strong>&lt;USERNAME&gt;.github.io</strong>, then the value of baseURL will be <strong>https://&lt;USERNAME&gt;.github.io/</strong>. If the GitHub repository has any other name, then the value will be <strong>https://&lt;USERNAME&gt;.github.io/&lt;REPOSITORY_NAME&gt;/</strong>. For instance, my GitHub username is <code>visionbike</code>, then:</p>
<ul>
<li>If the GitHub repository is named <code>visionbike.github.io</code>, then the baseURL will be <code>https://visionbike.github.io/</code>.</li>
<li>If the GitHub repository is named <code>visionbike-hugo</code>, then the baseURL will be <code>https://visionbike.github.io/visionbike-hugo/</code>.</li>
</ul>
</li>
<li>
<p><u><strong>title</strong></u>: This will be the title of your blog site as it appears at the top of a visitorâ€™s web browser when your site is open. It will also appear underneath your avatar, if one is present.</p>
</li>
<li>
<p><u><strong>theme</strong></u>: The name of the theme Hugo should use to render your site. In my example, this will be set to <code>PaperModX</code>, since that is the name of the theme I am using.</p>
</li>
</ul>
<p>Example contents of the <code>config.yml</code> file can be found below.</p>
<details class="admonition note"><summary class="admonition-title">config.yml</summary>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># base URL</span><span class="w">
</span><span class="w"></span><span class="nt">baseURL</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;http://visionbike.github.io/&#34;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># site title</span><span class="w">
</span><span class="w"></span><span class="nt">title</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Visionbike - Personal Blog of CV | DSP | ML notes&#34;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># paginate</span><span class="w">
</span><span class="w"></span><span class="nt">paginate</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># theme config</span><span class="w">
</span><span class="w"></span><span class="nt">theme</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;PaperModX&#34;</span><span class="w">
</span><span class="w"></span><span class="nt">themesdir</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;themes&#34;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># global config</span><span class="w">
</span><span class="w"></span><span class="nt">enableInlineShortcodes</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w"></span><span class="nt">enableRobotsTXT</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w"></span><span class="nt">buildDrafts</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w"></span><span class="nt">buildFuture</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w"></span><span class="nt">buildExpired</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w"></span><span class="nt">enableEmoji</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># css minify for speeding up site</span><span class="w">
</span><span class="w"></span><span class="nt">minify</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">disableXML</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">minifyOutput</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># site param config</span><span class="w">
</span><span class="w"></span><span class="nt">params</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># environment</span><span class="w">
</span><span class="w">  </span><span class="nt">env</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;production&#34;</span><span class="w">
</span><span class="w">  </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Visionbike - Personal Blog of CV | DSP | ML notes&#34;</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># color scheme: auto, dark, light</span><span class="w">
</span><span class="w">  </span><span class="nt">defaultTheme</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;dark&#34;</span><span class="w">
</span><span class="w">  </span><span class="nt">disableThemeToggle</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># header logo</span><span class="w">
</span><span class="w">  </span><span class="nt">logo</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">text</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Visionbike&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">icon</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;images/apple-touch-icon.png&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">iconHeight</span><span class="p">:</span><span class="w"> </span><span class="m">35</span><span class="w">
</span><span class="w">    </span><span class="nt">iconWidth</span><span class="p">:</span><span class="w"> </span><span class="m">35</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># profile-mode</span><span class="w">
</span><span class="w">  </span><span class="nt">profileMode</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">    </span><span class="nt">title</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Phuc Thanh-Thien Nguyen&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">subtitle</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;AI Researcher - Personal Blog of CV | DSP | ML notes&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">imageUrl</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;images/avatar-real.png&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">imageTitle</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;avatar-real&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">imageWidth</span><span class="p">:</span><span class="w"> </span><span class="m">180</span><span class="w">
</span><span class="w">    </span><span class="nt">imageHeight</span><span class="p">:</span><span class="w"> </span><span class="m">180</span><span class="w">
</span><span class="w">    </span><span class="nt">buttons</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">Archives</span><span class="w">
</span><span class="w">        </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="l">/archives/</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">Tags</span><span class="w">
</span><span class="w">        </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="l">/tags/</span><span class="w">
</span><span class="w">  </span><span class="c"># home-info-mode</span><span class="w">
</span><span class="w">  </span><span class="nt">homeInfoParams</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">title</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Phuc Thanh-Thien Nguyen&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">content</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;AI Researcher - Personal Blog of CV | DSP | ML notes&#34;</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># home social icons</span><span class="w">
</span><span class="w">  </span><span class="nt">socialIcons</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">github</span><span class="w">
</span><span class="w">      </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;https://github.com/visionbike/&#34;</span><span class="w">
</span><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">linkedIn</span><span class="w">
</span><span class="w">      </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;https://linkedin.com/in/nttphuc/&#34;</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># post config</span><span class="w">
</span><span class="w">  </span><span class="nt">author</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Visionbike&#34;</span><span class="w">
</span><span class="w">  </span><span class="nt">showCodeCopyButtons</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">displayFullLangName</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">showReadingTime</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">showWordCount</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">showPostNavLinks</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">showBreadCrumbs</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="nt">enableImageZoom</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># assets images</span><span class="w">
</span><span class="w">  </span><span class="nt">assets</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c"># disableFingerprinting: true</span><span class="w">
</span><span class="w">    </span><span class="nt">favicon</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;images/favicon.ico&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">favicon16x16</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;images/favicon-16x16.png&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">favicon32x32</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;images/favicon-32x32.png&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">appleTouchIcon</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;images/apple-touch-icon.png&#34;</span><span class="w">
</span><span class="w">    </span><span class="nt">safarPinnedTab</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;images/safari-pinned-tab.svg&#34;</span><span class="w">
</span><span class="w">
</span><span class="w">  </span><span class="c"># search page</span><span class="w">
</span><span class="w">  </span><span class="nt">fuseOpts</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">isCaseSensitive</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w">    </span><span class="nt">shouldSort</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">    </span><span class="nt">location</span><span class="p">:</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="w">    </span><span class="nt">distance</span><span class="p">:</span><span class="w"> </span><span class="m">1000</span><span class="w">
</span><span class="w">    </span><span class="nt">threshold</span><span class="p">:</span><span class="w"> </span><span class="m">0.4</span><span class="w">
</span><span class="w">    </span><span class="nt">minMatchCharLength</span><span class="p">:</span><span class="w"> </span><span class="m">0</span><span class="w">
</span><span class="w">    </span><span class="nt">keys</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&#34;title&#34;</span><span class="p">,</span><span class="w"> </span><span class="s2">&#34;permalink&#34;</span><span class="p">,</span><span class="w"> </span><span class="s2">&#34;summary&#34;</span><span class="p">,</span><span class="w"> </span><span class="s2">&#34;content&#34;</span><span class="p">]</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># laguage config</span><span class="w">
</span><span class="w"></span><span class="nt">languages</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">en</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">    </span><span class="c"># language code</span><span class="w">
</span><span class="w">    </span><span class="nt">languageCode</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;en&#34;</span><span class="w">
</span><span class="w">    </span><span class="c"># determines default content language: &#34;en&#34;, &#34;zh-cn&#34;, &#34;fr&#34;, &#34;vi&#34;, ...</span><span class="w">
</span><span class="w">    </span><span class="nt">defaultContentLanguage</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;en&#34;</span><span class="w">
</span><span class="w">    </span><span class="c"># menu language</span><span class="w">
</span><span class="w">    </span><span class="nt">menu</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">main</span><span class="p">:</span><span class="w">
</span><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Posts&#34;</span><span class="w">
</span><span class="w">          </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;/posts/&#34;</span><span class="w">
</span><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Tags&#34;</span><span class="w">
</span><span class="w">          </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;/tags/&#34;</span><span class="w">
</span><span class="w">          </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Archive&#34;</span><span class="w">
</span><span class="w">          </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;/archives/&#34;</span><span class="w">
</span><span class="w">          </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">4</span><span class="w">
</span><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Publish&#34;</span><span class="w">
</span><span class="w">          </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;/publish/&#34;</span><span class="w">
</span><span class="w">          </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;About&#34;</span><span class="w">
</span><span class="w">          </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span><span class="w">          </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;/about/&#34;</span><span class="w">
</span><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;Search&#34;</span><span class="w">
</span><span class="w">          </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">100</span><span class="w">
</span><span class="w">          </span><span class="nt">url</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;/search/&#34;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># for search page</span><span class="w">
</span><span class="w"></span><span class="nt">outputs</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">home</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="l">HTML</span><span class="w">
</span><span class="w">    </span>- <span class="l">RSS</span><span class="w">
</span><span class="w">    </span>- <span class="l">JSON</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="c"># syntax highlight</span><span class="w">
</span><span class="w"></span><span class="nt">pygmentsUseClasses</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w"></span><span class="nt">pygmentsCodeFences</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w"></span><span class="nt">markup</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">goldmark</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">renderer</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">unsafe</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">    </span><span class="nt">highlight</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">lineNos</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w">      </span><span class="nt">codeFences</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">      </span><span class="nt">noClasses</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span></code></pre></div></details>
<p>After modifying the configuration file accordingly, you can commit and push changes from your local repository to GitHub.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">git add config.yml
git commit -m <span class="s2">&#34;modify configuration file&#34;</span>
git push -u origin master
</code></pre></div><h2 id="6-creating-new-hugo-post">6. Creating New Hugo Post</h2>
<p>You are almost done finishing your personal blog!</p>
<p>To create the first post, you execute the <code>hugo new</code> command in the terminal.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">hugo new posts/first-post/index.md
</code></pre></div><p>The command will create a new folder named <code>first-post</code> with new Markdown file <code>index.md</code>, inside the <u><strong>content/posts</strong></u> directory. Creating a new directory for each single post helps you manage your resource better when images, media sources can be store directly in this directory. The Markdown file will contain the template for your first blog post and you can start  writing your content using Markdown syntax.</p>
<p>The contents of the <code>first-post.md</code> file will look like as:</p>
<div class="admonition note"><p class="admonition-title">first-post.md</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-markdown" data-lang="markdown">---
title: &#34;First Post&#34;
date: 2023-07-04T01:53:57+08:00
draft: true
---
</code></pre></div></div>
<p>You need to add content to the Markdown file and update the metadata header. In the metadata header, you will find information such as the post&rsquo;s title, publishing date and draft status. Change the value of the <strong>draft</strong> field from <code>true</code> to <code>false</code> to indicate that the post is ready to be published on your blog site. Your can also add other features supported by the installed theme for your post, i.e., comments, share buttons, navigation, etc.</p>
<p>The, you add the desired content to the body of the post. For instance, I added the line <strong>&ldquo;This is my first post! Hello world!&quot;</strong> at the bottom of the file. Feel free to customize the content to reflect your own thoughts and ideas in Markdown syntax.</p>
<p>After modifying the first blog post, you can use <code>git commit</code> to commit and push the changes from your local repository to GitHub.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">git add content/posts/first-post.md
git commit -m <span class="s2">&#34;add the first post&#34;</span>
git push -u origin master
</code></pre></div><h2 id="7-testing-the-hugo-configuration">7. Testing the Hugo Configuration</h2>
<p>Before hosting your blog to GitHub pages, make ensure Hugo can parse the configuration file and build our new blog post successfully.</p>
<p>In the local machine, you can run <code>hugo server</code> command to serve your site locally.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">hugo server --disableFastRender
</code></pre></div><p>It will watch for any changes in your files and automatically rebuild your site whenever there are updates. Hugo will provide a local development server address, i.e., <code>http://localhost:1313</code>, where you can access your site locally.</p>
<p>To parse the configuration and build your site, you simply run <code>hugo</code> command.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">hugo
</code></pre></div><p>If Hugo encounters any errors, they will be reported here. If the site is successfully built, then you will see output similar to the following.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">Start building sites â€¦ 
hugo v0.92.2+extended linux/amd64 <span class="nv">BuildDate</span><span class="o">=</span>2023-01-31T11:11:57Z <span class="nv">VendorInfo</span><span class="o">=</span>ubuntu:0.92.2-1ubuntu0.1

                   <span class="p">|</span> EN  
-------------------+-----
  Pages            <span class="p">|</span> <span class="m">13</span>  
  Paginator pages  <span class="p">|</span>  <span class="m">0</span>  
  Non-page files   <span class="p">|</span>  <span class="m">0</span>  
  Static files     <span class="p">|</span> <span class="m">18</span>  
  Processed images <span class="p">|</span>  <span class="m">0</span>  
  Aliases          <span class="p">|</span>  <span class="m">0</span>  
  Sitemaps         <span class="p">|</span>  <span class="m">1</span>  
  Cleaned          <span class="p">|</span>  <span class="m">0</span>  

Total in <span class="m">38</span> ms
</code></pre></div><h2 id="8-setting-up-github-actions-workflow">8. Setting Up GitHub Actions Workflow</h2>
<p>Lastly, the GitHub Actions workflow has to be prepared for automatically building and deploying your blog to GitHub Pages. This workflow is defined by a YAML file in the <u><strong>.github/workflows</strong></u> directory structure at the root of the project.</p>
<p>First, create the <code>workflows</code> folder.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">mkdir -p .github/workflows
</code></pre></div><p>The command will create the <u><strong>.github/workflows</strong></u> directory if it doesn&rsquo;t already exist. The <code>-p</code> option ensures that the parent directories are created if needed.</p>
<p>Then, we create a new file within the created folder directory, named <code>deploy_gh_pages.yaml</code> with the following contents.</p>
<div class="admonition note"><p class="admonition-title">deploy_gh_pages.yaml</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nn">---</span><span class="w">
</span><span class="w"></span><span class="nn">---</span><span class="w">
</span><span class="w"></span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">Deploy Hugo site via GitHub Pages</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">on</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">push</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">branches</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="l">master</span><span class="w"> </span><span class="c"># Set a branch to deploy</span><span class="w">
</span><span class="w">  </span><span class="nt">pull_request</span><span class="p">:</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="nt">jobs</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">deploy</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l">ubuntu-22.04</span><span class="w">
</span><span class="w">    </span><span class="nt">permissions</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">contents</span><span class="p">:</span><span class="w"> </span><span class="l">write</span><span class="w">
</span><span class="w">    </span><span class="nt">concurrency</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">group</span><span class="p">:</span><span class="w"> </span><span class="l">${{ github.workflow }}-${{ github.ref }}</span><span class="w">
</span><span class="w">    </span><span class="nt">steps</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l">actions/checkout@v3</span><span class="w">
</span><span class="w">        </span><span class="nt">with</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">submodules</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w"> </span><span class="c"># Fetch Hugo themes (true OR recursive)</span><span class="w">
</span><span class="w">          </span><span class="nt">fetch-depth</span><span class="p">:</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="c"># Fetch all history for .GitInfo and .Lastmod</span><span class="w">
</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">Setup Hugo</span><span class="w">
</span><span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l">peaceiris/actions-hugo@v2</span><span class="w">
</span><span class="w">        </span><span class="nt">with</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">hugo-version</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;latest&#34;</span><span class="w">
</span><span class="w">          </span><span class="nt">extended</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">Build</span><span class="w">
</span><span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l">hugo --minify</span><span class="w">
</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">Deploy</span><span class="w">
</span><span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l">peaceiris/actions-gh-pages@v3</span><span class="w">
</span><span class="w">        </span><span class="c"># If you&#39;re changing the branch from main,</span><span class="w">
</span><span class="w">        </span><span class="c"># also change the `master` in `refs/heads/master`</span><span class="w">
</span><span class="w">        </span><span class="c"># below accordingly.</span><span class="w">
</span><span class="w">        </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l">github.ref == &#39;refs/heads/master&#39;</span><span class="w">
</span><span class="w">        </span><span class="nt">with</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">github_token</span><span class="p">:</span><span class="w"> </span><span class="l">${{ secrets.GITHUB_TOKEN }}</span><span class="w">
</span><span class="w">          </span><span class="nt">publish_dir</span><span class="p">:</span><span class="w"> </span><span class="l">./public</span><span class="w">
</span></code></pre></div></div>
<p>The YAML file sets up the deployment process using Hugo and GitHub Pages. The workflow is triggered on a push to the <code>master</code> branch, and it uses the specified actions to build and deploy your blog. You can find more in <a href="https://github.com/peaceiris/actions-gh-pages"><strong>this</strong></a>.</p>
<p>Finally, we use <code>git</code> commands to commit and push the changes from your local repository to GitHub.</p>
<div class="highlight command"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">git add .github/workflows/deploy_gh_pages.yaml
git commit -m <span class="s2">&#34;Add GitHub Actions workflow&#34;</span>
git push -u origin master
</code></pre></div><h2 id="9-configuring-github-pages">9. Configuring GitHub Pages</h2>
<p>The GitHub Pages will allow GitHub to build automatically and serve our website whenever changes are made to the underlying repository.</p>
<p>First, we create new branch named <code>gh-page</code>. This branch will be used by GitHub Pages to build and serve your website. You can create the branch using the branch creation feature in your GitHub repository.</p>
<p><img loading="lazy" src="/posts/setting-up-personal-blog-with-hugo-and-gh-pages/create-gh-pages.png" type="" alt="Create gh-pages"  /></p>
<p>Then, go to the <code>Settings</code> tab near the top of your repository.</p>
<p><img loading="lazy" src="/posts/setting-up-personal-blog-with-hugo-and-gh-pages/repository-setting.png" type="" alt="Repository setting"  /></p>
<p>In the left hand pane, locate and click on the <code>Pages</code> category.</p>
<p><img loading="lazy" src="/posts/setting-up-personal-blog-with-hugo-and-gh-pages/gh-pages-setting.png" type="" alt="GitHub pages setting"  /></p>
<p>By default, GitHub Pages will be disabled for your repository. To enable it, we need to select a branch for GitHub Pages to build and serve our website from. Under the <code>Source</code> section in the middle pane, you will see a dropdown menu labeled <code>None</code>. Click on the dropdown menu and select the <code>gh-pages</code> branch. This tells GitHub Pages to build and serve your website from the <code>gh-pages</code> branch.</p>
<p><img loading="lazy" src="/posts/setting-up-personal-blog-with-hugo-and-gh-pages/select-deployment-branch.png" type="" alt="Select deployment branch"  /></p>
<p>After selecting the deployment branch, you will see a notification indicating where your site will be published. It will provide you with a URL where your website can be accessed.</p>
<p><img loading="lazy" src="/posts/setting-up-personal-blog-with-hugo-and-gh-pages/published-url.png" type="" alt="Published URL"  /></p>
<p>Wait for a few minutes to allow GitHub Pages to build and deploy your website. When the deployment completes, you can click on the URL provided in the notification to view your website. It may take some time for the changes to propagate and for your website to become accessible.</p>
<p><img loading="lazy" src="/posts/setting-up-personal-blog-with-hugo-and-gh-pages/site-demo.png" type="" alt="Site demo"  /></p>
<h2 id="conclusion">Conclusion</h2>
<p>Congratulations on setting up your blog using <strong>Hugo</strong>, <strong>Markdown</strong>, and <strong>GitHub Pages</strong>! This free and accessible solution enables you to create and share your technical knowledge with a wide audience. Happy blogging!</p>
<h2 id="reference">Reference</h2>
<ul>
<li>
<p><a href="https://chrisjhart.com/Creating-A-Simple-Free-Blog-Hugo/">How to Create a Simple, Free Blog with Hugo and GitHub Pages</a>.</p>
</li>
<li>
<p><a href="https://github.com/reorx/hugo-PaperModX">https://github.com/reorx/hugo-PaperModX</a>.</p>
</li>
<li>
<p><a href="https://gohugo.io/">https://gohugo.io/</a>.</p>
</li>
<li>
<p><a href="https://github.com/olOwOlo/hugo-theme-even/">https://github.com/olOwOlo/hugo-theme-even/</a>.</p>
</li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
