<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Setting Up NVIDIA CUDA on Windows 11 | Visionbike - Personal Blog of CV | DSP | ML notes</title>
<meta name=keywords content>
<meta name=description content="In this post, I will cover how to setup NVIDIA CUDA on Windows 11. To ensure a smooth setup process, it is crucial to follow the following steps:
 NVIDIA Drivers. Microsoft Visual Studio 2022 Community. NVIDIA CUDA Toolkit. NVIDIA cuDNN. TensorRT (optional). Miniforge (optional).  1. System Requirements To use CUDA, make sure your machine has a CUDA-capable GPU inside and the Microsoft Windows 11 should be updated 21H2 version.">
<meta name=author content="Visionbike">
<link rel=canonical href=http://visionbike.github.io/posts/setting-up-nvidia-cuda-on-windows-11/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.bfeaceca36889d51e73d9931f189f3cfb4e0393ea69bad26f042ab99d668e1d1.css integrity="sha256-v+rOyjaInVHnPZkx8Ynzz7TgOT6mm60m8EKrmdZo4dE=" rel="preload stylesheet" as=style>
<link rel=icon type=image/png href=/images/favicon.ico>
<link rel=apple-touch-icon href=/images/apple-touch-icon.png>
<link rel=icon type=image/png sizes=16x16 href=/images/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=/images/favicon-32x32.png>
<meta name=twitter:title content="Setting Up NVIDIA CUDA on Windows 11 | Visionbike - Personal Blog of CV | DSP | ML notes">
<meta name=twitter:description content="In this post, I will cover how to setup NVIDIA CUDA on Windows 11. To ensure a smooth setup process, it is crucial to follow the following steps:
 NVIDIA Drivers. Microsoft Visual Studio 2022 Community. NVIDIA CUDA Toolkit. NVIDIA cuDNN. TensorRT (optional). Miniforge (optional).  1. System Requirements To use CUDA, make sure your machine has a CUDA-capable GPU inside and the Microsoft Windows 11 should be updated 21H2 version.">
<meta property="og:title" content="Setting Up NVIDIA CUDA on Windows 11 | Visionbike - Personal Blog of CV | DSP | ML notes">
<meta property="og:description" content="In this post, I will cover how to setup NVIDIA CUDA on Windows 11. To ensure a smooth setup process, it is crucial to follow the following steps:
 NVIDIA Drivers. Microsoft Visual Studio 2022 Community. NVIDIA CUDA Toolkit. NVIDIA cuDNN. TensorRT (optional). Miniforge (optional).  1. System Requirements To use CUDA, make sure your machine has a CUDA-capable GPU inside and the Microsoft Windows 11 should be updated 21H2 version.">
<meta property="og:type" content="article">
<meta property="og:url" content="http://visionbike.github.io/posts/setting-up-nvidia-cuda-on-windows-11/">
<meta property="article:section" content="posts">
<meta property="article:published_time" content="2023-07-06T12:41:36+08:00">
<meta property="article:modified_time" content="2023-07-06T12:41:36+08:00">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://visionbike.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Setting Up NVIDIA CUDA on Windows 11","item":"http://visionbike.github.io/posts/setting-up-nvidia-cuda-on-windows-11/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Setting Up NVIDIA CUDA on Windows 11 | Visionbike - Personal Blog of CV | DSP | ML notes","name":"Setting Up NVIDIA CUDA on Windows 11","description":"In this post, I will cover how to setup NVIDIA CUDA on Windows 11. To ensure a smooth setup process, it is crucial to follow the following steps:\n NVIDIA Drivers. Microsoft Visual Studio 2022 Community. NVIDIA CUDA Toolkit. NVIDIA cuDNN. TensorRT (optional). Miniforge (optional).  1. System Requirements To use CUDA, make sure your machine has a CUDA-capable GPU inside and the Microsoft Windows 11 should be updated 21H2 version.","keywords":[],"wordCount":"2613","inLanguage":"en","datePublished":"2023-07-06T12:41:36+08:00","dateModified":"2023-07-06T12:41:36+08:00","author":{"@type":"Person","name":"Visionbike"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://visionbike.github.io/posts/setting-up-nvidia-cuda-on-windows-11/"},"publisher":{"@type":"Organization","name":"Visionbike - Personal Blog of CV | DSP | ML notes","logo":{"@type":"ImageObject","url":"http://visionbike.github.io/favicon.ico"}}}</script>
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
</noscript><link rel=stylesheet href=lib/fontawesome-free/all.min.css>
</head>
<body class="dark type-posts kind-page layout-" id=top><script data-no-instant>function switchTheme(a){switch(a){case'light':document.body.classList.remove('dark');break;case'dark':document.body.classList.add('dark');break;default:window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')}}function isDarkTheme(){return document.body.className.includes("dark")}function getPrefTheme(){return localStorage.getItem("pref-theme")}function setPrefTheme(a){switchTheme(a),localStorage.setItem("pref-theme",a)}const toggleThemeCallbacks={};toggleThemeCallbacks.main=a=>{a?setPrefTheme('light'):setPrefTheme('dark')},window.addEventListener('toggle-theme',function(){const a=isDarkTheme();for(const b in toggleThemeCallbacks)toggleThemeCallbacks[b](a)});function toggleThemeListener(){window.dispatchEvent(new CustomEvent('toggle-theme'))}</script>
<script>(function(){const b='dark',a=getPrefTheme(),c=a||b;switchTheme(c)})()</script>
<script>document.addEventListener('DOMContentLoaded',function(){var a=document.querySelectorAll('.command code');a.forEach(function(a){var b=a.textContent.split('\n'),c,d;a.textContent='',c=a.dataset.lang||'bash',d=c==='cmd'?'>':'$',c==='python'&&(d='>>>'),b.forEach(function(c,e){c.trim()!==''&&(a.innerHTML+='<span class="prompt">'+d+'</span> '+c,e!==b.length-1&&(a.innerHTML+='<br>'))})})})</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=http://visionbike.github.io/ accesskey=h title="Visionbike (Alt + H)">
<img src=http://visionbike.github.io/images/apple-touch-icon.png alt=logo aria-label=logo height=35 width=35>Visionbike</a>
<span class=logo-switches>
</span>
</div>
<ul id=menu>
<li>
<a href=http://visionbike.github.io/posts/ title=Posts class=active>Posts
</a>
</li>
<li>
<a href=http://visionbike.github.io/tags/ title=Tags>Tags
</a>
</li>
<li>
<a href=http://visionbike.github.io/archives/ title=Archive>Archive
</a>
</li>
<li>
<a href=http://visionbike.github.io/publish/ title=Publish>Publish
</a>
</li>
<li>
<a href=http://visionbike.github.io/about/ title=About>About
</a>
</li>
<li>
<a href=http://visionbike.github.io/search/ title="Search (Alt + /)" data-no-instant accesskey=/>Search
</a>
</li>
</ul>
</nav>
</header>
<main class="main post">
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=http://visionbike.github.io/>Home</a>&nbsp;»&nbsp;<a href=http://visionbike.github.io/posts/>Posts</a></div><h1 class=post-title>Setting Up NVIDIA CUDA on Windows 11</h1>
<div class=post-meta><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar" style="user-select:text"><rect x="3" y="4" width="18" height="18" rx="2" ry="2" style="user-select:text"/><line x1="16" y1="2" x2="16" y2="6" style="user-select:text"/><line x1="8" y1="2" x2="8" y2="6" style="user-select:text"/><line x1="3" y1="10" x2="21" y2="10" style="user-select:text"/></svg>
<span>July 6, 2023</span></span><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text" style="user-select:text"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z" style="user-select:text"/><polyline points="14 2 14 8 20 8" style="user-select:text"/><line x1="16" y1="13" x2="8" y2="13" style="user-select:text"/><line x1="16" y1="17" x2="8" y2="17" style="user-select:text"/><polyline points="10 9 9 9 8 9" style="user-select:text"/></svg>
<span>2613 words</span></span><span class=meta-item><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke="currentcolor" stroke-width="2" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>13 min</span></span>
</div>
</header> <div class="toc side right">
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#1-system-requirements aria-label="1. System Requirements">1. System Requirements</a></li>
<li>
<a href=#2-installing-mamba aria-label="2. Installing Mamba">2. Installing Mamba</a></li>
<li>
<a href=#3-installing-nvidia-cuda-toolkit aria-label="3. Installing NVIDIA CUDA Toolkit">3. Installing NVIDIA CUDA Toolkit</a></li>
<li>
<a href=#4-installing-nvidia-cudnn aria-label="4. Installing NVIDIA cuDNN">4. Installing NVIDIA cuDNN</a></li>
<li>
<a href=#5-installing-nvidia-tensorrt-optional aria-label="5. Installing NVIDIA TensorRT (Optional)">5. Installing NVIDIA TensorRT (Optional)</a></li>
<li>
<a href=#conclusion aria-label=Conclusion>Conclusion</a></li>
<li>
<a href=#reference aria-label=Reference>Reference</a>
</li>
</ul>
</div>
</details>
</div>
<div class=post-content><p>In this post, I will cover how to setup <strong>NVIDIA CUDA</strong> on Windows 11. To ensure a smooth setup process, it is crucial to follow the following steps:</p>
<ul>
<li>NVIDIA Drivers.</li>
<li>Microsoft Visual Studio 2022 Community.</li>
<li>NVIDIA CUDA Toolkit.</li>
<li>NVIDIA cuDNN.</li>
<li>TensorRT (optional).</li>
<li>Miniforge (optional).</li>
</ul>
<h2 id=1-system-requirements>1. System Requirements<a hidden class=anchor aria-hidden=true href=#1-system-requirements>¶</a></h2>
<p>To use CUDA, make sure your machine has a CUDA-capable GPU inside and the <strong>Microsoft Windows 11</strong> should be updated <strong>21H2</strong> version.</p>
<p>You can verify if your machine has CUDA-supported GPU through <strong>Display Adapters</strong> section in the <strong>Windows Device Manager</strong>. Here you will find the vendor name and model of your GPU.</p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/device-manager.png type alt="device manager"></p>
<p>You also need to install <strong>Microsft Visual Studio 2022 Community</strong> as the native compilter for x86_64 application. The download link os the latest version is <a href="https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community"><strong>here</strong></a> and install the <strong>Desktop development with C++</strong> workload.</p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/visual-studio-installation.png type alt="Visual Studio Installation"></p>
<p>If there is any NVIDIA CUDA Toolkit installed before, you need to uninstall before proceeding further, following these steps:</p>
<ol>
<li>Open the <strong>Settings > Apps > Installed Apps</strong>.</li>
<li>Scroll down and find NVIDIA CUDA applications.</li>
</ol>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-apps-list.png type alt="NVIDIA apps list"></p>
<ol start=3>
<li>Click to &ldquo;&mldr;&rdquo; button on the right and uninstall all NVIDIA GPU drivers and any associated software.</li>
</ol>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-app-uninstallation.png type alt="NVIDIA app uninstallation"></p>
<p>Then you need to install NVIDIA driver to communicate your computer with NVIDIA devices. You can find the suitable driver from this <a href="https://www.nvidia.com/download/index.aspx?lang=en-us"><strong>website</strong></a>.</p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-driver-installation.png type alt="NVIDIA Driver Installation"></p>
<p>After the installation is complete, reboot your system.</p>
<h2 id=2-installing-mamba>2. Installing Mamba<a hidden class=anchor aria-hidden=true href=#2-installing-mamba>¶</a></h2>
<p><a href=https://mamba.readthedocs.io/en/latest/user_guide/mamba.html><strong>Mamba</strong></a> is a command-line interfacer (CLI) to manage <code>conda</code>&rsquo;s environemts. For <code>mamba</code> configuration, please refer to <a href=https://conda.io/projects/conda/en/latest/user-guide/configuration/index.html><strong>conda documentation</strong></a>.</p>
<p>For the fresh installation, you can install <a href=https://github.com/conda-forge/miniforge><strong>Miniforge distribution</strong></a> >= <code>Miniforge3-22.3.1.0</code>. <strong>Miniforge</strong> comes with the popular <code>conda-forge</code> channel preconfigured, but you can modify the configuration to use any channel you like.</p>
<div class="admonition note"><p class=admonition-title>Installation</p>
<p>Follow the instaltion prompts, taking note of options to <strong>Create start menu shortcuts</strong> and <strong>Add Miniforge3 to my PATH environment variable</strong>.</p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/miniforge-installation.png type alt="Miniforge Installation"></p>
</div>
<p>After successful installation, you can use use the mamba commands as described in this <a href=https://mamba.readthedocs.io/en/latest/user_guide/mamba.html#mamba><strong>user guide</strong></a>.</p>
<div class="admonition note"><p class=admonition-title>Working with Conda Environment</p>
<p>The command using <code>mamba</code> is similar to the <code>conda</code> command.</p>
<ul>
<li>Create new environment</li>
</ul>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash>mamba create -n <span class=p>&amp;</span>lt<span class=p>;</span>ENV_NAME<span class=p>&amp;</span>gt<span class=p>;</span> <span class=nv>python</span><span class=o>=</span><span class=p>&amp;</span>lt<span class=p>;</span>VERSION<span class=p>&amp;</span>gt<span class=p>;</span>
</code></pre></div><ul>
<li>Activate an environment</li>
</ul>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash>mamba activate <span class=p>&amp;</span>lt<span class=p>;</span>ENV_NAME<span class=p>&amp;</span>gt<span class=p>;</span>
</code></pre></div><ul>
<li>Deactivate environment</li>
</ul>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash>mamba deactivate
</code></pre></div><ul>
<li>Delete an environment</li>
</ul>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash>mamba env remove -n <span class=p>&amp;</span>lt<span class=p>;</span>ENV_NAME<span class=p>&amp;</span>gt<span class=p>;</span>
</code></pre></div><ul>
<li>Show all created environments</li>
</ul>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash>mamba env list
</code></pre></div><p><strong>Remember to activate an environment first, do not install any packages in your base environment!</strong></p>
<ul>
<li>Install python packages</li>
</ul>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash>mamba install <span class=p>&amp;</span>lt<span class=p>;</span>PKG_NAME<span class=p>&amp;</span>gt<span class=p>;</span><span class=o>[=</span>VERSION<span class=o>]</span> <span class=o>[</span>-c <span class=p>&amp;</span>lt<span class=p>;</span>CHANNEL_NAME<span class=p>&amp;</span>gt<span class=p>;</span><span class=o>]</span>
</code></pre></div><p>When installing a package, you can optionally indicate specific additional channel that the packages are posted by community. The <code>conda-forge</code> is one of most common additional channels.</p>
<ul>
<li>Delete packages</li>
</ul>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash>mamba remove <span class=p>&amp;</span>lt<span class=p>;</span>PKG_NAME<span class=p>&amp;</span>gt<span class=p>;</span>
</code></pre></div><ul>
<li>Show all installed packages in the virtual environment</li>
</ul>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash>mamba list <span class=o>[</span>-n <span class=p>&amp;</span>lt<span class=p>;</span>ENV_NAME<span class=p>&amp;</span>gt<span class=p>;</span><span class=o>]</span>
</code></pre></div></div>
<div class="admonition note"><p class=admonition-title>Post-installation</p>
<p>After installation, you make sure that the <strong>Anaconda</strong> is not the default configured channel, seeing <a href=https://mamba.readthedocs.io/en/latest/user_guide/troubleshooting.html#defaults-channels><strong>this</strong></a>.</p>
<p><strong>DO NOT</strong> install anything into the <code>base</code> environment as this might break your installation. See <a href=https://mamba.readthedocs.io/en/latest/user_guide/troubleshooting.html#base-packages><strong>here</strong></a> for details.</p>
<p>The most convenient way to use the <strong>Mamba</strong> will be via the <strong>Miniforge Prompt</strong> installed in the <strong>Start Menu</strong>.</p>
</div>
<h2 id=3-installing-nvidia-cuda-toolkit>3. Installing NVIDIA CUDA Toolkit<a hidden class=anchor aria-hidden=true href=#3-installing-nvidia-cuda-toolkit>¶</a></h2>
<p>You can visit the <a href=https://developer.nvidia.com/cuda-downloads><strong>NVIDIA Developer website for CUDA Toolkit</strong></a> TO get the latest version of NVIDIA CUDA Toolkit. For previous versions, you can check from the <a href=https://developer.nvidia.com/cuda-toolkit-archive><strong>Archive of Previous CUDA Releases</strong></a> page.</p>
<p>On the dowload page, you choose the appropriate version based on your system.</p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cuda-toolkit-download-page.png type alt="Download CUDA Toolkit"></p>
<p>Then, you locate the downloaded installer file and double-click on it to start the installation process. Follow the on-screen instructions provided by the installer.</p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cuda-toolkit-installation.png type alt="NVIDIA CUDA Toolkit install"></p>
<p>Once the installation is completed, you check environment variables <code>CUDA_PATH</code> and <code>PATH</code> to ensure that your system recognizes <strong>NVIDIA CUDA Toolkit</strong>.</p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cuda-path-1.png type alt="NVIDIA CUDA Path 1"></p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cuda-path-2.png type alt="NVIDIA CUDA Path 2"></p>
<details class="admonition info"><summary class=admonition-title>Verify CUDA Toolkit Installation</summary>
<p>You can verify the installation by running the following command in command prompt.</p>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>nvcc --version
</code></pre></div><p>If the installation was successful, you should see the CUDA version information displayed.</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Tue_Feb_27_16:28:36_Pacific_Standard_Time_2024
Cuda compilation tools, release 12.4, V12.4.99
Build cuda_12.4.r12.4/compiler.33961263_0
</code></pre></div><p>It is important to verify that the <strong>NVIDIA CUDA Toolkit</strong> can find and communicate correctly with CUDA-compatible hardware. To do this, you need to compile and run some sample programs.</p>
<p>CUDA samples are located in <a href=https://github.com/nvidia/cuda-samples><strong>https://github.com/nvidia/cuda-samples</strong></a>. To use the samples, clone the project, build the samples in <code>cuda-samples</code> directory using <strong>MVSC 2022 compiler</strong> and run them following the instruction on the Github page.</p>
<p>To verify a correct configuration of the hardware and software, it is highly recommended that you build and run the <code>deviceQuery</code> sample program.</p>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>deviceQuery.exe
</code></pre></div><p>If CUDA is installed and configured correctly, the output should look similar as below:</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>deviceQuery.exe Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: <span class=s2>&#34;NVIDIA GeForce RTX 3070 Ti Laptop GPU&#34;</span>
  CUDA Driver Version / Runtime Version          12.4 / 12.4
  CUDA Capability Major/Minor version number:    8.6
  Total amount of global memory:                 8192 MBytes (8589410304 bytes)
  <span class=p>(</span>046<span class=p>)</span> Multiprocessors, (128) CUDA Cores/MP:    5888 CUDA Cores
  GPU Max Clock rate:                            1410 MHz (1.41 GHz)
  Memory Clock rate:                             7001 Mhz
  Memory Bus Width:                              256-bit
  L2 Cache Size:                                 4194304 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total shared memory per multiprocessor:        102400 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  1536
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
  Run time limit on kernels:                     Yes
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  CUDA Device Driver Mode (TCC or WDDM):         WDDM (Windows Display Driver Model)
  Device supports Unified Addressing (UVA):      Yes
  Device supports Managed Memory:                Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      No
  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0
  Compute Mode:
     <span class=p>&lt;</span> Default <span class=p>(</span>multiple host threads can use ::cudaSetDevice(<span class=p>)</span> with device simultaneously) &gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 12.4, CUDA Runtime Version = 12.4, NumDevs = 1
Result = PASS
</code></pre></div><p>By running the <code>bandwidthTest</code> program, you can ensure that the system and CUDA-capable device are able to communicate correctly.</p>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>bandwidthText.exe
</code></pre></div><p>The output shoud be here.</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>[CUDA Bandwidth Test] - Starting...
Running on...

 Device 0: NVIDIA GeForce RTX 3070 Ti Laptop GPU
 Quick Mode

 Host to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(GB/s)
   32000000                     11.3

 Device to Host Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(GB/s)
   32000000                     13.9

 Device to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)        Bandwidth(GB/s)
   32000000                     361.1

Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
</code></pre></div><p>To see a graphical representation, you can run the <code>particles</code> sample program.</p>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>particles.exe
</code></pre></div><p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cuda-particle-sample.png type alt="NVIDIA CUDA Particle Sample"></p>
</details>
<p>The installed <strong>NVIDIA CUDA Toolkit</strong> provides the necessary libraries, compilers, and tools for developing and running CUDA-accelerated applications and machine learning models.</p>
<h2 id=4-installing-nvidia-cudnn>4. Installing NVIDIA cuDNN<a hidden class=anchor aria-hidden=true href=#4-installing-nvidia-cudnn>¶</a></h2>
<p><strong>cuDNN (CUDA Deep Neural Network Library)</strong> is a GPU-accelerated library specifically designed and colaborated with <strong>NVIDA CUDA Toolkit</strong> to accelerate deep neural network computations. By utilizing <strong>cuDNN</strong>, deep learning frameworks can leverage the parallel processing capabilities of NVIDIA GPUs, leading to significant speed improvements in training and inference of deep neural networks.</p>
<p>You can visit <a href=https://developer.nvidia.com/rdp/cudnn-download><strong>NVIDIA Developer website for cuDNN</strong></a> for the latest version. You will need to register or log in to your NVIDIA Developer account in order to access the cuDNN download files. If you don&rsquo;t have an account, you can create one for free.</p>
<p>Once you are logged in, choose the appropriate <strong>cuDNN</strong> version based on the <strong>NVIDIA CUDA Toolkit</strong> version and operating system. There are two main installation options:</p>
<ol>
<li><strong>Graphical installation</strong> (executable): the graphical installer bundles the available per-CUDA cuDNN verions in one package.</li>
<li><strong>Tarball installation</strong> (zip): per-CUDA cuDNN versions are provided as saperate tarballs (zip). These <code>.zip</code> archives do not replace the graphical installer and are not meant for general consumption, as they are not installers. These <code>zip</code> archives can be found at <a href=https://developer.download.nvidia.com/compute/cudnn/redist/cudnn/windows-x86_64/><strong>this</strong></a>.</li>
</ol>
<p>Select one of two options for installing <strong>cuDNN</strong>. In this post, I will install <strong>cuDNN</strong> via the Tarball installation option.</p>
<p>Once download the <code>zip</code> archive, you unzip the <strong>cuDNN</strong> package.</p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cudnn-unzip.png type alt="NVIDIA cuDNN Unzip"></p>
<p>Copy the following files from the unzipped package into the <strong>NVIDIA cuDNN</strong> directory created by yourself.</p>
<ul>
<li>Copy <code>bin\cudnn*.h</code> to <strong>C:Program Files\NVIDIA\CUDNN\vx.y\bin</strong>.</li>
<li>Copy <code>include\cudnn*.h</code> to <strong>C:\Program Files\NVIDIA\CUDNN\vx.y\include</strong>.</li>
<li>Copy <code>lib\x64\cudnn*.lib</code> to <strong>C:\Program Files\NVIDIA\CUDNN\vx.y\lib</strong>.</li>
</ul>
<p>You must replace <code>x.y</code> with your specific <strong>cuDNN</strong> version.</p>
<p>Set the environment variable to point to where <strong>cuDNN</strong> is located and add <code>bin</code> directory path to <code>PATH</code> environment variable.</p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cudnn-path.png type alt="NVIDIA cuDNN Path"></p>
<p>For upgrading <strong>cuDNN</strong>, the remove the path to the directory containing <strong>cuDNN</strong> from <code>PATH</code> environment variable.</p>
<details class="admonition info"><summary class=admonition-title>Verify cuDNN Installation</summary>
<p>The <strong>cuDNN</strong> samples can be found <a href=https://developer.download.nvidia.com/compute/cudnn/redist/cudnn_samples/source/><strong>here</strong></a> and download and extract the <code>tar.xz</code> archive.</p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-cudnn-samples.png type alt="NVIDIA cuDNN Samples"></p>
<p>Since this is cross-platform LINUX samples, you need to install <a href=https://cmake.org/download/><strong>CMAKE</strong></a> and use it to compile the <strong>cuDNN</strong> samples.</p>
<p>Inside the <code>cuda_sample_vx</code> directory (<code>x</code> as the <strong>cuDNN</strong> version), make the comment to line 21 <code># add_subdirectory(mnistCUDNN)</code>.</p>
<p>Run the following command in the command prompt.</p>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd><span class=k>mkdir</span> build <span class=p>&amp;&amp;</span> <span class=k>cd</span> build
cmake -G <span class=s2>&#34;Visual Studio 17 2022&#34;</span> -D cuDNN_INCLUDE_DIR=<span class=s2>&#34;C:\Program Files\NVIDIA\CUDNN\v9.0\include&#34;</span> -D cuDNN_LIBRARY_DIR=<span class=s2>&#34;C:\Program Files\NVIDIA\CUDNN\v9.0\lib&#34;</span> ..
cmake --build . --config Release
</code></pre></div><p>By running the <code>conv_sample</code> program, you can ensure the <strong>cuDNN</strong> work in your system.</p>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>.\conv_sample\Release\conv_sample.exe
</code></pre></div><p>The result should be as following:</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>Executing: conv_sample.exe
Using format CUDNN_TENSOR_NCHW (for INT8x4 and INT8x32 tests use CUDNN_TENSOR_NCHW_VECT_C)
Testing single precision
====USER DIMENSIONS====
input dims are 1, 32, 4, 4
filter dims are 32, 32, 1, 1
output dims are 1, 32, 4, 4
====PADDING DIMENSIONS====
padded input dims are 1, 32, 4, 4
padded filter dims are 32, 32, 1, 1
padded output dims are 1, 32, 4, 4
Testing conv
<span class=se>^^^^</span> CUDA : elapsed = 0.0127218 sec,
Test PASSED
Testing half precision (math in single precision)
====USER DIMENSIONS====
input dims are 1, 32, 4, 4
filter dims are 32, 32, 1, 1
output dims are 1, 32, 4, 4
====PADDING DIMENSIONS====
padded input dims are 1, 32, 4, 4
padded filter dims are 32, 32, 1, 1
padded output dims are 1, 32, 4, 4
Testing conv
<span class=se>^^^^</span> CUDA : elapsed = 0.0029165 sec,
Test PASSED
</code></pre></div></details>
<p>For <strong>Visual Studio</strong> project, add <strong>cuDNN</strong> by following steps:</p>
<ul>
<li>Right-click on the project name in <strong>Solution Explorer</strong> and choose **Properties.</li>
<li>Click <strong>VC++ Directories</strong> and append <code>C:\Program Files\NVIDIA\CUDNN\v9.x\include</code> to the <strong>Include Direcotries</strong> field.</li>
<li>Click <strong>Linker > General</strong> and append <code>C:\Program Files\NVIDIA\CUDNN\v9.x\lib</code> to the <strong>Additional Library Directories</strong> field.</li>
<li>Click <strong>Linker > Input</strong> and append <code>cudnn.h</code> to the <strong>Additional Dependencies</strong> field and click <strong>OK</strong>.</li>
</ul>
<h2 id=5-installing-nvidia-tensorrt-optional>5. Installing NVIDIA TensorRT (Optional)<a hidden class=anchor aria-hidden=true href=#5-installing-nvidia-tensorrt-optional>¶</a></h2>
<p><strong>NVIDIA TensorRT</strong> is a C++ library that facilitates high-performance inference NVIDIA graphic processing units (GPUs). <strong>TensorRT</strong> takes a trained network, which consists of a network definition and a set of trained parameters, and produces a highly optimized runtime engine that performs inference for that network.</p>
<p><strong>TensorRT</strong> provides APIs via C++ and Python that help to express deep learning model via the Network Definition API or load a pre-defined model via the ONNX parser that allow <strong>TensorRT</strong> to optimize and run them on the NVIDIA GPU.</p>
<p><strong>TensorRT</strong> also include optional high speed mixed precision capabilities with difference NVIDIA architectures.</p>
<p>You can download the <strong>TensorRT</strong> at <a href=https://developer.nvidia.com/tensorrt/download/10x><strong>here</strong></a>. For Windows architecture, there is only <code>zip</code> archive installation.</p>
<p>Unzip the <code>zip</code> archive and copy files in <code>lib</code>, <code>include</code> direcotries to <strong>C:\Program Files\NVIDIA\TensorRT\v10.0</strong> directory created by yourself. Then, you add <code>lib</code> directory path to <code>PATH</code> environment variable.</p>
<p><img loading=lazy src=/posts/setting-up-nvidia-cuda-on-windows-11/nvidia-tensorrt-path.png type alt="NVIDIA TensorRT Path"></p>
<details class="admonition info"><summary class=admonition-title>Verify TensorRT Installation</summary>
<p>Inside the <code>zip</code> archive also include the sample programs. To verify the installation is working, you should open a Visual Studio file from one of the samples, such as <code>sampleOnnxMNIST</code>.In the project, ensure that following is presented in the Visual Studio Solution project properties:</p>
<ul>
<li>Add <code>C:\Program Files\NVIDIA\TensorRT\v10.0\lib</code> to <code>PATH</code> and <strong>VC++ Directories > Executable Directories</strong>.</li>
<li>Add <code>C:\Program Files\NVIDIA\TensorRT\v10.0\include</code> to <strong>C/C++ > General > Additional Directories</strong>.</li>
<li>Add <code>nvinfer.lib</code> and <code>.lib</code> files that that the projects requires to <strong>Linker > Input > Additional Dependencies</strong>.</li>
</ul>
<p>Compile the source code and run the example.</p>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>.\bin\sample_onnx_mnist.exe
</code></pre></div><p>The output should be as following:</p>
<div class=highlight><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd><span class=p>&amp;&amp;&amp;&amp;</span> RUNNING TensorRT.sample_onnx_mnist [TensorRT v100000] # .\sample_onnx_mnist.exe
[04/08/2024-18:12:10] [I] Building and running a GPU inference engine for Onnx MNIST
[04/08/2024-18:12:10] [I] [TRT] [MemUsageChange] Init CUDA: CPU +109, GPU +0, now: CPU 18227, GPU 1091 (MiB)
[04/08/2024-18:12:18] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +2597, GPU +310, now: CPU 21109, GPU 1401 (MiB)
[04/08/2024-18:12:18] [I] [TRT] ----------------------------------------------------------------
[04/08/2024-18:12:18] [I] [TRT] Input filename:   ../data/mnist/mnist.onnx
[04/08/2024-18:12:18] [I] [TRT] ONNX IR version:  0.0.3
[04/08/2024-18:12:18] [I] [TRT] Opset version:    8
[04/08/2024-18:12:18] [I] [TRT] Producer name:    CNTK
[04/08/2024-18:12:18] [I] [TRT] Producer version: 2.5.1
[04/08/2024-18:12:18] [I] [TRT] Domain:           ai.cntk
[04/08/2024-18:12:18] [I] [TRT] Model version:    1
[04/08/2024-18:12:18] [I] [TRT] Doc string:
[04/08/2024-18:12:18] [I] [TRT] ----------------------------------------------------------------
[04/08/2024-18:12:18] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/08/2024-18:12:20] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[04/08/2024-18:12:20] [I] [TRT] Total Host Persistent Memory: 26400
[04/08/2024-18:12:20] [I] [TRT] Total Device Persistent Memory: 0
[04/08/2024-18:12:20] [I] [TRT] Total Scratch Memory: 0
[04/08/2024-18:12:20] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 6 steps to complete.
[04/08/2024-18:12:20] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.8572ms to assign 3 blocks to 6 nodes requiring 32256 bytes.
[04/08/2024-18:12:20] [I] [TRT] Total Activation Memory: 31744
[04/08/2024-18:12:20] [I] [TRT] Total Weights Memory: 26152
[04/08/2024-18:12:20] [I] [TRT] Engine generation completed in 1.68333 seconds.
[04/08/2024-18:12:20] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 5 MiB
[04/08/2024-18:12:20] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 3036 MiB
[04/08/2024-18:12:20] [I] [TRT] Loaded engine size: 0 MiB
[04/08/2024-18:12:21] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[04/08/2024-18:12:21] [I] Input:
[04/08/2024-18:12:21] [I] @@@@@@@@@@@@@@@@@@@@@@@@@@@@
<span class=p>@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class=p>@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class=p>@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class=p>@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class=p>@@@@@@@@@@</span>=   ++++#++=*@@@@@
<span class=p>@@@@@@@@</span>#.            *@@@@@
<span class=p>@@@@@@@@</span>=             *@@@@@
<span class=p>@@@@@@@@</span>.   .. ...****%@@@@@
<span class=p>@@@@@@@@</span>: .%@@#@@@@@@@@@@@@@
<span class=p>@@@@@@@</span>%  -@@@@@@@@@@@@@@@@@
<span class=p>@@@@@@@</span>%  -@@*@@@*@@@@@@@@@@
<span class=p>@@@@@@@</span>#  :#- ::. ::=@@@@@@@
<span class=p>@@@@@@@</span>-             -@@@@@@
<span class=p>@@@@@@</span>%.              *@@@@@
<span class=p>@@@@@@</span>#     :==*+==   *@@@@@
<span class=p>@@@@@@</span><span class=nv>%---%</span>%@@@@@@@.  *@@@@@
<span class=p>@@@@@@@@@@@@@@@@@@@</span>+  *@@@@@
<span class=p>@@@@@@@@@@@@@@@@@@@</span>=  *@@@@@
<span class=p>@@@@@@@@@@@@@@@@@@</span>*   *@@@@@
<span class=p>@@@@@</span><span class=nv>%+%</span>@@@@@@@@<span class=nv>%.   .%</span>@@@@@
<span class=p>@@@@@</span>*  .******=    -@@@@@@@
<span class=p>@@@@@</span>*             .#@@@@@@@
<span class=p>@@@@@</span>*            =%@@@@@@@@
<span class=p>@@@@@@</span>%#+++=     =@@@@@@@@@@
<span class=p>@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class=p>@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>
<span class=p>@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span>

[04/08/2024-18:12:21] [I] Output:
[04/08/2024-18:12:21] [I]  Prob 0  0.0000 Class 0:
[04/08/2024-18:12:21] [I]  Prob 1  0.0000 Class 1:
[04/08/2024-18:12:21] [I]  Prob 2  0.0000 Class 2:
[04/08/2024-18:12:21] [I]  Prob 3  0.0000 Class 3:
[04/08/2024-18:12:21] [I]  Prob 4  0.0000 Class 4:
[04/08/2024-18:12:21] [I]  Prob 5  1.0000 Class 5: **********
[04/08/2024-18:12:21] [I]  Prob 6  0.0000 Class 6:
[04/08/2024-18:12:21] [I]  Prob 7  0.0000 Class 7:
[04/08/2024-18:12:21] [I]  Prob 8  0.0000 Class 8:
[04/08/2024-18:12:21] [I]  Prob 9  0.0000 Class 9:
[04/08/2024-18:12:21] [I]
<span class=p>&amp;&amp;&amp;&amp;</span> PASSED TensorRT.sample_onnx_mnist [TensorRT v100000] # .\sample_onnx_mnist.exe
</code></pre></div></details>
<p>If you are using <strong>TensorRT Python API</strong>, make sure <strong>CUDA-Python</strong> is installed in your system or your virtual environment.</p>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>mamba create -n tensorrt_env pip wheel
mamba activate tensorrt_env
</code></pre></div><ul>
<li>Installing from <strong>PyPI</strong>, <strong>TensorRT</strong> runtime wheels</li>
</ul>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-cmd data-lang=cmd>pip install cuda-python
pip install --pre --upgrade tensorrt
pip install --pre --upgrade tensorrt_lean tensorrt_dispatch
</code></pre></div><p>To verify the installation is working, use python code.</p>
<div class="highlight command"><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>tensorrt</span>
<span class=nb>print</span><span class=p>(</span><span class=n>tensorrt</span><span class=o>.</span><span class=n>__version__</span><span class=p>)</span>
<span class=k>assert</span><span class=p>(</span><span class=n>tensorrt</span><span class=o>.</span><span class=n>Builder</span><span class=p>(</span><span class=n>tensorrt</span><span class=o>.</span><span class=n>Logger</span><span class=p>()))</span>

<span class=kn>import</span> <span class=nn>tensorrt_lean</span> <span class=k>as</span> <span class=nn>trtl</span>
<span class=nb>print</span><span class=p>(</span><span class=n>trtl</span><span class=o>.</span><span class=n>__version__</span><span class=p>)</span>
<span class=k>assert</span> <span class=n>trtl</span><span class=o>.</span><span class=n>Runtime</span><span class=p>(</span><span class=n>trt</span><span class=o>.</span><span class=n>Logger</span><span class=p>())</span>

<span class=kn>import</span> <span class=nn>tensorrt_dispatch</span> <span class=k>as</span> <span class=nn>trtd</span>
<span class=nb>print</span><span class=p>(</span><span class=n>trtd</span><span class=o>.</span><span class=n>__version__</span><span class=p>)</span>
<span class=k>assert</span> <span class=n>trtd</span><span class=o>.</span><span class=n>Runtime</span><span class=p>(</span><span class=n>trt</span><span class=o>.</span><span class=n>Logger</span><span class=p>())</span>
</code></pre></div><p>The <code>tensorrt/samples</code> directory also provides the samples that utilize with the <strong>TensorRT</strong>, you can follow instructions from <code>README.md</code> to run samples.</p>
<h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>¶</a></h2>
<p>By following these steps and installing the required software, you will have an CUDA-ready environment in Windows 11 system for further machine learnin/deep learning applications. This environment will provide the necessary tools and libraries for GPU-accelerated computing and Python package management.</p>
<h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>¶</a></h2>
<ul>
<li><a href=https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/>CUDA Installation Guide for Microsoft Windows</a>.</li>
<li><a href=https://medium.com/geekculture/install-cuda-and-cudnn-on-windows-linux-52d1501a8805>Install CUDA and CUDNN on Windows & Linux</a>.</li>
<li><a href=https://medium.com/@Gunter-Pearson/installing-latest-tensorflow-version-with-cuda-cudnn-and-gpu-support-on-windows-11-pc-e41fac5c5795>Installing Latest TensorFlow version with CUDA, cudNN and GPU support on Windows 11 PC</a>.</li>
</ul>
</div>
<footer class=post-footer>
<nav class=paginav>
<a class=prev href=http://visionbike.github.io/posts/setitng-up-nvidia-cuda-on-wsl2/>
<span class=title>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left" style="user-select:text"><line x1="19" y1="12" x2="5" y2="12" style="user-select:text"/><polyline points="12 19 5 12 12 5" style="user-select:text"/></svg>&nbsp;Prev Page</span>
<br>
<span>Setting Up NVIDIA CUDA on WSL 2</span>
</a>
<a class=next href=http://visionbike.github.io/posts/setting-up-personal-blog-with-hugo-and-gh-pages/>
<span class=title>Next Page&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right" style="user-select:text"><line x1="5" y1="12" x2="19" y2="12" style="user-select:text"/><polyline points="12 5 19 12 12 19" style="user-select:text"/></svg>
</span>
<br>
<span>Setting Up a Personal Blog With Hugo and GitHub Pages</span>
</a>
</nav>
</footer>
<div class=comments-separator></div>
</article>
</main>
<footer class=footer>
<span>&copy; 2024 <a href=http://visionbike.github.io/>Visionbike - Personal Blog of CV | DSP | ML notes</a></span><span style=display:inline-block;margin-left:1em>
<a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA</a>
</span>
<span style=display:inline-block;margin-left:1em>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
    <a href=https://github.com/reorx/hugo-PaperModX/ rel=noopener target=_blank>PaperModX</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>(function(){const b='1'=='1';if(b)return;let a=document.getElementById("theme-toggle");a.removeEventListener('click',toggleThemeListener),a.addEventListener('click',toggleThemeListener)})()</script>
<script>(function(){let a=document.getElementById('menu');a&&(a.scrollLeft=localStorage.getItem("menu-scroll-position"),a.onscroll=function(){localStorage.setItem("menu-scroll-position",a.scrollLeft)});const b=''=='1',c='1'=='1';if(window.matchMedia('(prefers-reduced-motion: reduce)').matches||b||c)return;document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})})()</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>if(window.scrollListeners)for(const a of scrollListeners)window.removeEventListener('scroll',a);window.scrollListeners=[]</script>
<script src=/js/medium-zoom.min.js data-no-instant></script>
<script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script>
<script>(function(){const h='1'=='1';if(!h)return;if(!document.querySelector('.toc')){console.log('no toc found, ignore toc scroll');return}const i=window.scrollListeners,c=document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id]'),d='active';let a=c[0];e(a).classList.add(d);const g=()=>{const b=[];for(const a of c)if(j(a)<5)b.push(a);else break;b.length>0?newActiveHeading=b[b.length-1]:newActiveHeading=c[0],a!=newActiveHeading&&(e(a).classList.remove(d),a=newActiveHeading,e(a).classList.add(d))};let b=null;const f=()=>{b!==null&&clearTimeout(b),b=setTimeout(g,50)};window.addEventListener('scroll',f,!1),i.push(f);function e(a){const b=encodeURI(a.getAttribute('id')).toLowerCase();return document.querySelector(`.toc ul li a[href="#${b}"]`)}function j(a){if(!a.getClientRects().length)return 0;let b=a.getBoundingClientRect();return b.top}})()</script>
<script>mediumZoom('.entry-cover img'),mediumZoom('.post-content img:not([no-zoom])')</script>
<script src=/js/instantclick.min.js data-no-instant></script>
<script data-no-instant>InstantClick.init()</script>
</body>
</html>